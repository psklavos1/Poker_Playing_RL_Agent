{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# utils.py: general function used throughout the project"
      ],
      "metadata": {
        "id": "i8rYVH9tKM0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Card:\n",
        "    '''\n",
        "    Card stores the suit and rank of a single card\n",
        "\n",
        "    Note:\n",
        "        The suit variable in a standard card game should be one of [S, H, D, C, BJ, RJ] meaning [Spades, Hearts, Diamonds, Clubs, Black Joker, Red Joker]\n",
        "        Similarly the rank variable should be one of [A, 2, 3, 4, 5, 6, 7, 8, 9, T, J, Q, K]\n",
        "    '''\n",
        "    suit = None\n",
        "    rank = None\n",
        "    valid_suit = ['S', 'H', 'D', 'C']\n",
        "    valid_rank = ['A', '2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K']\n",
        "\n",
        "    def __init__(self, suit, rank):\n",
        "        ''' Initialize the suit and rank of a card\n",
        "\n",
        "        Args:\n",
        "            suit: string, suit of the card, should be one of valid_suit\n",
        "            rank: string, rank of the card, should be one of valid_rank\n",
        "        '''\n",
        "        self.suit = suit\n",
        "        self.rank = rank\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if isinstance(other, Card):\n",
        "            return self.rank == other.rank and self.suit == other.suit\n",
        "        else:\n",
        "            # don't attempt to compare against unrelated types\n",
        "            return NotImplemented\n",
        "\n",
        "    def __hash__(self):\n",
        "        suit_index = Card.valid_suit.index(self.suit)\n",
        "        rank_index = Card.valid_rank.index(self.rank)\n",
        "        return rank_index + 100 * suit_index\n",
        "\n",
        "    def __str__(self):\n",
        "        ''' Get string representation of a card.\n",
        "\n",
        "        Returns:\n",
        "            string: the combination of rank and suit of a card. Eg: AS, 5H, JD, 3C, ...\n",
        "        '''\n",
        "        return self.rank + self.suit\n",
        "\n",
        "    def get_index(self):\n",
        "        ''' Get index of a card.\n",
        "\n",
        "        Returns:\n",
        "            string: the combination of suit and rank of a card. Eg: 1S, 2H, AD, BJ, RJ...\n",
        "        '''\n",
        "        return self.suit+self.rank\n",
        "\n",
        "\n",
        "def rank2int(rank):\n",
        "    ''' Get the coresponding number of a rank.\n",
        "\n",
        "    Args:\n",
        "        rank(str): rank stored in Card object\n",
        "\n",
        "    Returns:\n",
        "        (int): the number corresponding to the rank\n",
        "\n",
        "    Note:\n",
        "        1. If the input rank is an empty string, the function will return -1.\n",
        "        2. If the input rank is not valid, the function will return None.\n",
        "    '''\n",
        "    if rank == '':\n",
        "        return -1\n",
        "    elif rank.isdigit():\n",
        "        if int(rank) >= 2 and int(rank) <= 10:\n",
        "            return int(rank)\n",
        "        else:\n",
        "            return None\n",
        "    elif rank == 'A':\n",
        "        return 14\n",
        "    elif rank == 'T':\n",
        "        return 10\n",
        "    elif rank == 'J':\n",
        "        return 11\n",
        "    elif rank == 'Q':\n",
        "        return 12\n",
        "    elif rank == 'K':\n",
        "        return 13\n",
        "    return None\n",
        "\n",
        "def elegent_form(card):\n",
        "    ''' Get a elegent form of a card string\n",
        "\n",
        "    Args:\n",
        "        card (string): A card string\n",
        "\n",
        "    Returns:\n",
        "        elegent_card (string): A nice form of card\n",
        "    '''\n",
        "    suits = {'S': '♠', 'H': '♥', 'D': '♦', 'C': '♣','s': '♠', 'h': '♥', 'd': '♦', 'c': '♣' }\n",
        "    rank = '10' if card[1] == 'T' else card[1]\n",
        "\n",
        "    return suits[card[0]] + rank\n",
        "\n",
        "def print_card(cards):\n",
        "    ''' Nicely print a card or list of cards\n",
        "\n",
        "    Args:\n",
        "        card (string or list): The card(s) to be printed\n",
        "    '''\n",
        "    if cards is None:\n",
        "        cards = [None]\n",
        "    if isinstance(cards, str):\n",
        "        cards = [cards]\n",
        "\n",
        "    lines = [[] for _ in range(9)]\n",
        "\n",
        "    for card in cards:\n",
        "        if card is None:\n",
        "            lines[0].append('┌─────────┐')\n",
        "            lines[1].append('│░░░░░░░░░│')\n",
        "            lines[2].append('│░░░░░░░░░│')\n",
        "            lines[3].append('│░░░░░░░░░│')\n",
        "            lines[4].append('│░░░░░░░░░│')\n",
        "            lines[5].append('│░░░░░░░░░│')\n",
        "            lines[6].append('│░░░░░░░░░│')\n",
        "            lines[7].append('│░░░░░░░░░│')\n",
        "            lines[8].append('└─────────┘')\n",
        "        else:\n",
        "            if isinstance(card, Card):\n",
        "                elegent_card = elegent_form(card.suit + card.rank)\n",
        "            else:\n",
        "                elegent_card = elegent_form(card)\n",
        "            suit = elegent_card[0]\n",
        "            rank = elegent_card[1]\n",
        "            if len(elegent_card) == 3:\n",
        "                space = elegent_card[2]\n",
        "            else:\n",
        "                space = ' '\n",
        "\n",
        "            lines[0].append('┌─────────┐')\n",
        "            lines[1].append('│{}{}       │'.format(rank, space))\n",
        "            lines[2].append('│         │')\n",
        "            lines[3].append('│         │')\n",
        "            lines[4].append('│    {}    │'.format(suit))\n",
        "            lines[5].append('│         │')\n",
        "            lines[6].append('│         │')\n",
        "            lines[7].append('│       {}{}│'.format(space, rank))\n",
        "            lines[8].append('└─────────┘')\n",
        "\n",
        "    for line in lines:\n",
        "        print ('   '.join(line))\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_AY9T5WBKDKf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# config.py"
      ],
      "metadata": {
        "id": "zqhNE9tmJ9AF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "HcU8eZ-oJuJa"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "# from utils import rank2int\n",
        "\n",
        "cards = ['T', 'J', 'Q', 'K', 'A']\n",
        "actions = {0:'fold', 1:'check', 2:'bet', 3:'call', 4:'raise'}\n",
        "table_cards = list(itertools.combinations_with_replacement(cards, 2))\n",
        "\n",
        "def generate_state_space():\n",
        "    state_space = {}\n",
        "    id = 0\n",
        "    for player_card in cards:\n",
        "        state_space[(player_card, None)] = id  # Round 1 state with no table cards\n",
        "        id+=1\n",
        "\n",
        "        for table_card in table_cards:\n",
        "            state_space[(player_card, table_card)] = id  # Round 2 state with table cards\n",
        "            id+=1\n",
        "\n",
        "    state_space[(\"Terminal\", None)] = id # Terminal state where the showdown is happening\n",
        "\n",
        "    # print(\"States:\\n\",state_space)\n",
        "    # print(\"States:\\n\",len(state_space))\n",
        "    return state_space\n",
        "\n",
        "def generate_transition_model(adversary,state_space):\n",
        "    transition_model = {}\n",
        "\n",
        "    for id, state in enumerate(state_space):\n",
        "\n",
        "        player_card, table_cards = state\n",
        "        transition_model[id] = {}\n",
        "\n",
        "        if table_cards is None:\n",
        "            # First round transition model\n",
        "            for action in actions:\n",
        "                transition_model[id][action] = pre_flop_transition(state,action,adversary,state_space)\n",
        "        else:\n",
        "            # Second round transition model\n",
        "            for action in actions:\n",
        "                transition_model[id][action] = post_flop_transition(state,action,adversary,state_space)\n",
        "        # print(\"State\", state , \" Transition: \" ,transition_model[id], \"\\n\\n\")\n",
        "\n",
        "    # print(\"Transitions:\\n\",transition_model[state_space[('T',None)]][1])\n",
        "    # print(transition_model[state_space[('K', ('J', 'A'))]])\n",
        "\n",
        "    return transition_model\n",
        "\n",
        "\n",
        "def pre_flop_transition(state, action, adversary,state_space):\n",
        "    if adversary == 0:\n",
        "        return pre_flop_random(state, action,state_space)\n",
        "    elif adversary == 1:\n",
        "        return pre_flop_threshold_loose(state, action,state_space)\n",
        "    else:\n",
        "        return pre_flop_threshold_tight(state, action,state_space)\n",
        "\n",
        "def post_flop_transition(state, action, adversary,state_space):\n",
        "    if adversary == 0:\n",
        "        return post_flop_random(state, action,state_space)\n",
        "    elif adversary == 1:\n",
        "        return post_flop_threshold_loose(state, action,state_space)\n",
        "    else:\n",
        "        return post_flop_threshold_tight(state, action,state_space)\n",
        "\n",
        "\n",
        "def get_next_states_with_player_card(player_card,state_space):\n",
        "    return [state for state in state_space if state[0] == player_card and state[1]]\n",
        "\n",
        "def append_mult_states(transition,all_states,reward,terminal,state_space):\n",
        "    for next_state in all_states:\n",
        "        connections = 0\n",
        "        my_card = next_state[0]\n",
        "        table_cards = next_state[1]\n",
        "        for table_card in table_cards:\n",
        "            if my_card == table_card: connections +=1\n",
        "\n",
        "        num_combs = 0\n",
        "        if connections == 2:\n",
        "            num_combs = 1\n",
        "            transition.append(((3/19)*(2/18)/num_combs, state_space[next_state], reward ,terminal))\n",
        "        elif connections == 1:\n",
        "            num_combs = 4\n",
        "            transition.append(((3/19)+(3/19)-(3/19)*(2/18)/num_combs, state_space[next_state], reward ,terminal))\n",
        "        else:\n",
        "            num_combs = 10\n",
        "            transition.append(((1-(3/19)*(2/18)-(3/19)-(3/19)+(3/19)*(2/18))/num_combs, state_space[next_state], reward ,terminal))\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "#                                                                         #\n",
        "#                                                                         #\n",
        "#--------------------- TRANSITION MODELS GENERATION ----------------------#\n",
        "#                                                                         #\n",
        "#                                                                         #\n",
        "###########################################################################\n",
        "\n",
        "def pre_flop_random(state, action,state_space):\n",
        "    player_card, _ = state\n",
        "\n",
        "    transition = []\n",
        "    if player_card == \"Terminal\":\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "    else:\n",
        "        post_flop_states = get_next_states_with_player_card(player_card,state_space)\n",
        "        # [(probability, next_state, reward, terminal)]\n",
        "        if action == 0:\n",
        "            transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "        elif action == 1:\n",
        "            append_mult_states(transition,post_flop_states,1,False,state_space)\n",
        "        elif action == 2:\n",
        "            append_mult_states(transition,post_flop_states,2,False,state_space)\n",
        "        elif action == 3:\n",
        "            append_mult_states(transition,post_flop_states,2,False,state_space)\n",
        "        else: # raise\n",
        "            append_mult_states(transition,post_flop_states,5,False,state_space)\n",
        "    return transition\n",
        "\n",
        "#############################################################################################\n",
        "def pre_flop_threshold_loose(state, action,state_space):\n",
        "    player_card, _ = state\n",
        "\n",
        "    transition = []\n",
        "    if player_card == \"Terminal\":\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "    else:\n",
        "        post_flop_states = get_next_states_with_player_card(player_card,state_space)\n",
        "        if(player_card == 'A'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], -3, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,1,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,3,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,2,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,5,False,state_space)\n",
        "\n",
        "        elif(player_card == 'K'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], -3, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,-2,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,5,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states, 4,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states, 2,False,state_space)\n",
        "\n",
        "        elif(player_card == 'Q'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)],-2 , True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states, 2,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states, 2,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states, 4,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,-3,False,state_space)\n",
        "        elif(player_card == 'J'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], 3, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,5,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,-3,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,-4,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "        else: #(player_card == 'T'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], 3, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,5,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,-4,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "    return transition\n",
        "\n",
        "#############################################################################################\n",
        "def pre_flop_threshold_tight(state, action,state_space):\n",
        "    player_card, _ = state\n",
        "\n",
        "    transition = []\n",
        "    if player_card == \"Terminal\":\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "    else:\n",
        "        post_flop_states = get_next_states_with_player_card(player_card,state_space)\n",
        "        if(player_card == 'A'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1,state_space[(\"Terminal\", None)], -5, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,-3,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,4,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,3,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,5,False,state_space)\n",
        "\n",
        "        elif(player_card == 'K'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], -4, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,-2,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,4,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,1,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,2,False,state_space)\n",
        "\n",
        "        elif(player_card == 'Q'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], -2, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,0,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,4,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,3,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,-4,False,state_space)\n",
        "        elif(player_card == 'J'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], 1, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,3,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,4,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "        else: #(player_card == 'T'):\n",
        "            # [(probability, next_state, reward, terminal)]\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], 1, True))\n",
        "            elif action == 1:\n",
        "                append_mult_states(transition,post_flop_states,3,False,state_space)\n",
        "            elif action == 2:\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "            elif action == 3:\n",
        "                append_mult_states(transition,post_flop_states,1,False,state_space)\n",
        "            else: # raise\n",
        "                append_mult_states(transition,post_flop_states,-5,False,state_space)\n",
        "    return transition\n",
        "\n",
        "####################################### POST FLOP #############################################\n",
        "def post_flop_random(state, action,state_space):\n",
        "    player_card, table_cards = state\n",
        "    transition = []\n",
        "\n",
        "    if player_card == \"Terminal\":\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "\n",
        "    terminal_state = len(state_space)-1\n",
        "\n",
        "    if action == 0:\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], -5, True))\n",
        "    elif action == 1:\n",
        "        transition.append((1,terminal_state,-5,True))\n",
        "    elif action == 2:\n",
        "        transition.append((1,terminal_state,-5,True))\n",
        "    elif action == 3:\n",
        "        transition.append((1,terminal_state,-5,True))\n",
        "    else: # raise\n",
        "        transition.append((1,terminal_state,5,True))\n",
        "    return transition\n",
        "\n",
        "#############################################################################################\n",
        "def post_flop_threshold_loose(state, action,state_space):\n",
        "\n",
        "    player_card, table_cards = state\n",
        "    transition = []\n",
        "\n",
        "    if player_card == \"Terminal\":\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "\n",
        "    terminal_state = len(state_space)-1\n",
        "    sorted_table_cards = sorted(table_cards, key=lambda x: rank2int(x), reverse=True)\n",
        "    connections = [1 if player_card == sorted_table_cards[i] else 0 for i in range(len(table_cards)) ]\n",
        "    # If there is a triplet\n",
        "    if sum(connections) == 2:\n",
        "        if action == 0:\n",
        "            transition.append((1,state_space[(\"Terminal\", None)], -5, True))\n",
        "        elif action == 1:\n",
        "            transition.append((1,terminal_state,-5,True))\n",
        "        elif action == 2:\n",
        "            transition.append((1,terminal_state,3,True))\n",
        "        elif action == 3:\n",
        "            transition.append((1,terminal_state,2,True))\n",
        "        else: # raise\n",
        "            transition.append((1,terminal_state,5,True))\n",
        "\n",
        "    # 1 pair\n",
        "    elif sum(connections) == 1:\n",
        "        # top pair\n",
        "        if connections[0] == 1:\n",
        "            if action == 0:\n",
        "                transition.append((1, state_space[(\"Terminal\", None)], -5, True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,3,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,2,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,5,True))\n",
        "        # second pair\n",
        "        else:\n",
        "            if action == 0:\n",
        "                transition.append((1,state_space[(\"Terminal\", None)], -4, True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,-3,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,5,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,2,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,2,True))\n",
        "    # High card\n",
        "    else:\n",
        "        if action == 0:\n",
        "            transition.append((1,state_space[(\"Terminal\", None)], 3 , True))\n",
        "        elif action == 1:\n",
        "            transition.append((1,terminal_state,1,True))\n",
        "        elif action == 2:\n",
        "            transition.append((1,terminal_state, -2 ,True))\n",
        "        elif action == 3:\n",
        "            transition.append((1,terminal_state,-5,True))\n",
        "        else: # raise\n",
        "            transition.append((1,terminal_state,-5,True))\n",
        "        # if player_card == 'A':\n",
        "        #     if action == 0:\n",
        "        #         transition.append((1,state_space[(player_card, None)], -3 , True))\n",
        "        #     elif action == 1:\n",
        "        #         transition.append((1,terminal_state,1,True))\n",
        "        #     elif action == 2:\n",
        "        #         transition.append((1,terminal_state, 2 ,True))\n",
        "        #     elif action == 3:\n",
        "        #         transition.append((1,terminal_state,5,True))\n",
        "        #     else: # raise\n",
        "        #         transition.append((1,terminal_state,-5,True))\n",
        "        # elif player_card == 'K':\n",
        "        #     if action == 0:\n",
        "        #         transition.append((1, state_space[(player_card, None)], -1, True))\n",
        "        #     elif action == 1:\n",
        "        #         transition.append((1,terminal_state,-1,True))\n",
        "        #     elif action == 2:\n",
        "        #         transition.append((1,terminal_state,1,True))\n",
        "        #     elif action == 3:\n",
        "        #         transition.append((1,terminal_state,5,True))\n",
        "        #     else: # raise\n",
        "        #         transition.append((1,terminal_state,-5,True))\n",
        "        # else: # for Q,J ,T, very difficult to win\n",
        "        #     if action == 0:\n",
        "        #         transition.append((1,state_space[(player_card, None)], 5, True))\n",
        "        #     elif action == 1:\n",
        "        #         transition.append((1,terminal_state,5,True))\n",
        "        #     elif action == 2:\n",
        "        #         transition.append((1,terminal_state,-4,True))\n",
        "        #     elif action == 3:\n",
        "        #         transition.append((1,terminal_state,-5,True))\n",
        "        #     else: # raise\n",
        "        #         transition.append((1,terminal_state,-5,True))\n",
        "    return transition\n",
        "#############################################################################################\n",
        "def post_flop_threshold_tight(state, action,state_space):\n",
        "\n",
        "    player_card, table_cards = state\n",
        "    transition = []\n",
        "\n",
        "    if player_card == \"Terminal\":\n",
        "        transition.append((1, state_space[(\"Terminal\", None)], 0, True))\n",
        "\n",
        "    terminal_state = len(state_space)-1\n",
        "    sorted_table_cards = sorted(table_cards, key=lambda x: rank2int(x), reverse=True)\n",
        "    connections = [1 if player_card == sorted_table_cards[i] else 0 for i in range(len(table_cards)) ]\n",
        "\n",
        "    # For this speciic opponent the fold action will be modeled as\n",
        "    # fold if fold available else bluff\n",
        "\n",
        "    # If there is a triplet\n",
        "    if sum(connections) == 2:\n",
        "        if action == 0:\n",
        "            transition.append((1, terminal_state, -3, True))\n",
        "        elif action == 1:\n",
        "            transition.append((1,terminal_state,-5,True))\n",
        "        elif action == 2:\n",
        "            transition.append((1,terminal_state,3,True))\n",
        "        elif action == 3:\n",
        "            transition.append((1,terminal_state,2,True))\n",
        "        else: # raise\n",
        "            transition.append((1,terminal_state,5,True))\n",
        "\n",
        "    # 1 pair\n",
        "    elif sum(connections) == 1:\n",
        "        # top pair\n",
        "        if connections[0] == 1:\n",
        "            if action == 0:\n",
        "                transition.append((1,terminal_state, -3, True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,3,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,2,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,5,True))\n",
        "        # second pair raises only with top so we take advantage with bluff\n",
        "        else:\n",
        "            if action == 0:\n",
        "                transition.append((1, terminal_state, 5, True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,2,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,-3,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,-4,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "    # High card\n",
        "    else:\n",
        "        if player_card == 'A':\n",
        "            if action == 0:\n",
        "                transition.append((1,terminal_state, 5,True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,3,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "        elif player_card == 'K':\n",
        "            if action == 0:\n",
        "                transition.append((1,terminal_state, 4,True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,3,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "        else: # for Q,J ,T, very difficult to win\n",
        "            if action == 0:\n",
        "                transition.append((1,terminal_state, 3, True))\n",
        "            elif action == 1:\n",
        "                transition.append((1,terminal_state,5,True))\n",
        "            elif action == 2:\n",
        "                transition.append((1,terminal_state,-4,True))\n",
        "            elif action == 3:\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "            else: # raise\n",
        "                transition.append((1,terminal_state,-5,True))\n",
        "    return transition\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# human_agent,py: To play the game with user inputs"
      ],
      "metadata": {
        "id": "hdxaFso2Lata"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class HumanAgent():\n",
        "\n",
        "    def __init__(self):\n",
        "       self.random = np.random\n",
        "\n",
        "    def step(self,state):\n",
        "        legal_actions = state['legal_actions']\n",
        "\n",
        "        while True:\n",
        "            print(\"Legal actions\", str(legal_actions))\n",
        "            action = input(\"Select one of the legal actions:\")\n",
        "            if action in legal_actions:\n",
        "                return action\n",
        "            else: print(\"Invalid Input!\")\n",
        "\n",
        "    def get_type(self):\n",
        "        return \"Human Agent\""
      ],
      "metadata": {
        "id": "TGM2EV-YJ4sr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# random_agent.py"
      ],
      "metadata": {
        "id": "6YqqmOVyLpKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class RandomAgent():\n",
        "    def __init__(self):\n",
        "       self.random = np.random\n",
        "\n",
        "    def step(self,state):\n",
        "        legal_actions = state['legal_actions']\n",
        "        return self.random.choice(legal_actions)\n",
        "\n",
        "    def get_type(self):\n",
        "        return \"Random Agent\""
      ],
      "metadata": {
        "id": "tmmP-1syLxma"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# threshold_agent.py"
      ],
      "metadata": {
        "id": "LI34dxLbLtla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# from utils import rank2int\n",
        "\n",
        "\n",
        "class ThresholdAgent():\n",
        "    def __init__(self, aggro = True):\n",
        "       self.random = np.random\n",
        "       self.aggro = aggro\n",
        "\n",
        "    def loose_play(self,state):\n",
        "        # Case we have only one choice\n",
        "        if len(state['legal_actions']) == 1:\n",
        "            return state['legal_actions'][0]\n",
        "        rand = np.random.random()\n",
        "        # Preflop strategy\n",
        "        if state['round'] == 0:\n",
        "            if state['hand'][0][1] == 'A' or state['hand'][0][1] == 'K' or state['hand'][0][1] == 'Q':\n",
        "                return state['legal_actions'][-1]\n",
        "\n",
        "            else:\n",
        "                if 'check' in state['legal_actions']:\n",
        "                    return 'check'\n",
        "                else: return 'call'\n",
        "\n",
        "        else: # Post Flop\n",
        "            num_of_connections = 0\n",
        "            # check if he has connection to board\n",
        "            for i in range(len(state['public_cards'])):\n",
        "                if state['hand'][0][1] == state['public_cards'][i][1]:\n",
        "                    num_of_connections += 1\n",
        "            # with connection bet (play most aggresive option)\n",
        "            if num_of_connections > 0:\n",
        "                return state['legal_actions'][-1]\n",
        "            else:\n",
        "                # else if he has nothing leave\n",
        "                return state['legal_actions'][-1] if rand<0.1 else state['legal_actions'][0]\n",
        "\n",
        "\n",
        "    def tight_play(self,state):\n",
        "        # Case we have only one choice\n",
        "        if len(state['legal_actions']) == 1:\n",
        "            return state['legal_actions'][0]\n",
        "        rand = np.random.random()\n",
        "        # Preflop strategy\n",
        "        if state['round'] == 0:\n",
        "            if state['hand'][0][1] == 'A':\n",
        "                if 'bet' in state['legal_actions']:\n",
        "                    return 'bet'\n",
        "                else:\n",
        "                    return 'raise' if 'raise' in state['legal_actions'] else 'call'\n",
        "            elif state['hand'][0][1] == 'K':\n",
        "                return 'bet' if 'bet' in state['legal_actions'] else 'call'\n",
        "            elif state['hand'][0][1] == 'Q':\n",
        "                return 'check' if 'check' in state['legal_actions'] else 'call'\n",
        "            else:\n",
        "                return 'check' if 'check' in state['legal_actions'] else 'fold'\n",
        "\n",
        "        else: # Post Flop\n",
        "            public_ranks = (state['public_cards'][0][1], state['public_cards'][1][1])\n",
        "            sorted_table_cards = sorted(public_ranks, key=lambda x: rank2int(x), reverse=True)\n",
        "            connections = [1 if state['hand'][0][1] == sorted_table_cards[i] else 0 for i in range(len(sorted_table_cards)) ]\n",
        "            # with connection\n",
        "            if sum(connections) > 0:\n",
        "                if sum(connections) > 0:\n",
        "                    return 'bet' if 'bet' in state['legal_actions'] else 'call'\n",
        "                else:\n",
        "                    # return 'check' if 'check' in state['legal_actions'] else 'call'\n",
        "                    return state['legal_actions'][0]\n",
        "            else:\n",
        "                # else if he has nothing leave\n",
        "                return state['legal_actions'][0]\n",
        "\n",
        "\n",
        "    def step(self,state):\n",
        "        if self.aggro:\n",
        "            return self.loose_play(state)\n",
        "        else:\n",
        "            return self.tight_play(state)\n",
        "\n",
        "    def get_type(self):\n",
        "        return \"Threshold Loose Agent\" if self.aggro else \"Threshold Tight Agent\""
      ],
      "metadata": {
        "id": "fCfO1uxFLkwg"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# policy_iteration.py"
      ],
      "metadata": {
        "id": "gSRUwAzrLkKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "# from utils import rank2int\n",
        "# from config import generate_state_space, generate_transition_model\n",
        "\n",
        "class PolicyIterationAgent():\n",
        "\n",
        "    def __init__(self,adversary):\n",
        "        self.V = None\n",
        "        self.prev_V = None\n",
        "        self.Q = None\n",
        "        self.new_pi = None\n",
        "        self.pi = None\n",
        "        self.policy = None\n",
        "\n",
        "        self.random = np.random\n",
        "        self.adversary_type = adversary\n",
        "\n",
        "        self.cards = ['T', 'J', 'Q', 'K', 'A']\n",
        "\n",
        "        # The actions are modeled through pick_action(), to take represent 2\n",
        "        # different choices depending on the options available.\n",
        "        # The choices could be one of the 2 groups [check, bet] and [fold, call.raise](mostly)\n",
        "        # Below are the representations for each action\n",
        "        # fold => bet/fold (bluff)\n",
        "        # check => check/fold\n",
        "        # bet => bet/call\n",
        "        # call => check/call\n",
        "        # raise => bet/raise\n",
        "        self.actions = {0:'fold', 1:'check', 2:'bet', 3:'call', 4:'raise'}\n",
        "        self.table_cards = list(itertools.combinations_with_replacement(self.cards, 2))\n",
        "\n",
        "        self.state_space = generate_state_space()\n",
        "        self.transition_model = generate_transition_model(self.adversary_type,self.state_space)\n",
        "        # print(len(self.state_space))\n",
        "\n",
        "        # print(len(self.transition_model))\n",
        "\n",
        "    def get_type(self):\n",
        "        return \"Policy Iteration Agent\"\n",
        "\n",
        "\n",
        "    # policy iteration is simple, it will call alternatively policy evaluation then policy improvement, till the policy converges.\n",
        "    def policy_iteration(self, P, gamma = 1, epsilon = 1e-10):\n",
        "        t = 0\n",
        "        random_actions = np.random.choice(tuple(P[0].keys()), len(P))     # start with random actions for each state\n",
        "        # print(random_actions)\n",
        "        pi = lambda s: {s:a for s, a in enumerate(random_actions)}[s]     # and define your initial policy pi_0 based on these action (remember, we are passing policies around as python \"functions\", hence the need for this second line)\n",
        "\n",
        "        # print(\"print\\n\",P[0][1])\n",
        "        while True:\n",
        "            old_pi = {s: pi(s) for s in range(len(P))}  #keep the old policy to compare with new\n",
        "            V = self.policy_evaluation(pi,P,gamma,epsilon)   #evaluate latest policy --> you receive its converged value function\n",
        "            pi = self.policy_improvement(V,P,gamma)          #get a better policy using the value function of the previous one just calculated\n",
        "\n",
        "            t += 1\n",
        "            if old_pi == {s:pi(s) for s in range(len(P))}: # you have converged to the optimal policy if the \"improved\" policy is exactly the same as in the previous step\n",
        "                break\n",
        "        print('converged after %d iterations' %t) #keep track of the number of (outer) iterations to converge\n",
        "        return V,pi\n",
        "\n",
        "    def policy_evaluation(self,pi, P, gamma = 1.0, epsilon = 1e-10):  #inputs: (1) policy to be evaluated, (2) model of the environment (transition probabilities, etc., see previous cell), (3) discount factor (with default = 1), (4) convergence error (default = 10^{-10})\n",
        "        t = 0   #there's more elegant ways to do this\n",
        "        prev_V = np.zeros(len(P)) # use as \"cost-to-go\", i.e. for V(s')\n",
        "        while True:\n",
        "            V = np.zeros(len(P)) # current value function to be learnerd\n",
        "            for s in range(len(P)):  # do for every state\n",
        "                # calculate one Bellman step --> i.e., sum over all probabilities of transitions and reward for that state, the action suggested by the (fixed) policy, the reward earned (dictated by the model), and the cost-to-go from the next state (which is also decided by the model)\n",
        "\n",
        "                for prob, next_state, reward, done in P[s][pi(s)]:\n",
        "                    V[s] += prob * (reward + gamma * prev_V[next_state] * (not done))\n",
        "            if np.max(np.abs(prev_V - V)) < epsilon: #check if the new V estimate is close enough to the previous one;\n",
        "                break # if yes, finish loop\n",
        "            prev_V = V.copy() #freeze the new values (to be used as the next V(s'))\n",
        "            t += 1\n",
        "        return V\n",
        "\n",
        "    def policy_improvement(self, V, P, gamma=1):  # takes a value function (as the cost to go V(s')), a model, and a discount parameter\n",
        "        Q = np.zeros((len(P), len(P[0])), dtype=np.float64) #create a Q value array\n",
        "        for s in range(len(P)):        # for every state in the environment/model\n",
        "            for a in range(len(P[s])):  # and for every action in that state\n",
        "                for prob, next_state, reward, done in P[s][a]:  #evaluate the action value based on the model and Value function given (which corresponds to the previous policy that we are trying to improve)\n",
        "                    Q[s][a] += prob * (reward + gamma * V[next_state] * (not done))\n",
        "        new_pi = lambda s: {s:a for s, a in enumerate(np.argmax(Q, axis=1))}[s]  # this basically creates the new (improved) policy by choosing at each state s the action a that has the highest Q value (based on the Q array we just calculated)\n",
        "        # lambda is a \"fancy\" way of creating a function without formally defining it (e.g. simply to return, as here...or to use internally in another function)\n",
        "        # you can implement this in a much simpler way, by using just a few more lines of code -- if this command is not clear, I suggest to try coding this yourself\n",
        "\n",
        "        return new_pi\n",
        "\n",
        "    def get_state(self,raw_state):\n",
        "        public_cards = (raw_state['public_cards'][0][1], raw_state['public_cards'][1][1]) if raw_state['public_cards'] else None\n",
        "        public_cards = sorted(public_cards, key=lambda x: rank2int(x), reverse=False) if public_cards else None\n",
        "        state = (raw_state['hand'][0][1] , (public_cards[0],public_cards[1])) if public_cards else (state['hand'][0][1] , None)\n",
        "        return state\n",
        "\n",
        "    def step(self, state):\n",
        "        if not self.policy:\n",
        "            _,pi = self.policy_iteration(self.transition_model,gamma=.95)\n",
        "            pi = {s: pi(s) for s in range(len(self.transition_model))}\n",
        "            self.policy = pi\n",
        "\n",
        "        public_cards = (state['public_cards'][0][1], state['public_cards'][1][1]) if state['public_cards'] else None\n",
        "        public_cards = sorted(public_cards, key=lambda x: rank2int(x), reverse=False) if public_cards else None\n",
        "\n",
        "        s = (state['hand'][0][1] , (public_cards[0],public_cards[1])) if public_cards else (state['hand'][0][1] , None)\n",
        "        # print(state)\n",
        "        # print(s)\n",
        "        action_key = self.policy[self.state_space[s]]\n",
        "        chosen_action = self.actions[action_key]\n",
        "        # print(\"Initial decision:\" + chosen_action)\n",
        "\n",
        "        action  = self.pick_action(s, self.policy,state['legal_actions'])\n",
        "        # print(f\"Action Chosen By Policy Iteration Agent: {action}\")\n",
        "        return action\n",
        "\n",
        "    def pick_action(self,state, policy , legal_actions):\n",
        "\n",
        "        action_key = policy[self.state_space[state]]\n",
        "        chosen_action = self.actions[action_key]\n",
        "        # print(chosen_action)\n",
        "\n",
        "        if len(legal_actions) == 1:\n",
        "            return legal_actions[0]\n",
        "\n",
        "        if chosen_action in legal_actions:\n",
        "            return chosen_action\n",
        "        else:\n",
        "            if chosen_action == 'fold':\n",
        "                return 'bet'\n",
        "            elif chosen_action == 'check':\n",
        "                return 'fold'\n",
        "            elif chosen_action == 'bet': # bet call\n",
        "                if 'raise' in legal_actions:\n",
        "                   return 'call' #if rand<0.7 else 'raise'\n",
        "                else: return 'call'\n",
        "            elif chosen_action == 'call': # check call\n",
        "                return 'check' #if rand<0.8 else 'bet'\n",
        "            elif chosen_action == 'raise': # bet raise\n",
        "                return 'bet' if 'bet' in legal_actions else 'call'\n",
        "            else: return 'check'\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "RvAbhXI_MOtL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# q_learning.py"
      ],
      "metadata": {
        "id": "_JEir6QtMNyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# from utils import rank2int\n",
        "# from config import generate_state_space\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, id, learning_rate= .1, discount_factor=.95):\n",
        "        self.actions = ['fold', 'check', 'bet', 'call', 'raise']\n",
        "        self.num_actions = len(self.actions)\n",
        "        self.cards = ['T', 'J', 'Q', 'K', 'A']\n",
        "        self.table_cards = list(itertools.combinations_with_replacement(self.cards, 2))\n",
        "        self.my_id = id\n",
        "        self.state_space = generate_state_space()\n",
        "        self.num_states = len(self.state_space)\n",
        "\n",
        "        # Define a list to store the rewards for each episode\n",
        "        self.cumulative_rewards = []\n",
        "        self.avg_reward = []\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = 1\n",
        "\n",
        "        self.q_table = np.zeros((self.num_states, self.num_actions))\n",
        "\n",
        "    def get_type(self):\n",
        "        return \"Q-Learning Agent\"\n",
        "\n",
        "\n",
        "    def pick_action(self, state, legal_actions, epsilon):\n",
        "        action_values = self.q_table[self.state_space[state]]  # Get the Q-values for the current state\n",
        "        legal_action_values = [action_values[action] for action in range(len(legal_actions))]  # Filter Q-values for legal actions\n",
        "\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            # Explore by choosing a random action\n",
        "            action_index = np.random.choice(len(legal_action_values),1)[0]\n",
        "            action = legal_actions[action_index]  # Get the corresponding legal action\n",
        "        else:\n",
        "            # Exploit by choosing the action with maximum Q-value\n",
        "            action_index = np.argmax(legal_action_values)  # Get the index of the action with the maximum Q-value\n",
        "            action = legal_actions[action_index]  # Get the corresponding legal action\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        action_index = self.actions.index(action)\n",
        "        current_q = self.q_table[self.state_space[state], action_index]\n",
        "        max_q = np.max(self.q_table[self.state_space[next_state]])\n",
        "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_q - current_q)\n",
        "\n",
        "        self.q_table[self.state_space[state], action_index] = new_q\n",
        "\n",
        "    def get_state(self,raw_state):\n",
        "        public_cards = (raw_state['public_cards'][0][1], raw_state['public_cards'][1][1]) if raw_state['public_cards'] else None\n",
        "        public_cards = sorted(public_cards, key=lambda x: rank2int(x), reverse=False) if public_cards else None\n",
        "        state = (raw_state['hand'][0][1] , (public_cards[0],public_cards[1])) if public_cards else (raw_state['hand'][0][1] , None)\n",
        "        return state\n",
        "\n",
        "    def train_agent(self,game, adversary, num_episodes = 1_000_000,  threshold = 0.0001):\n",
        "        # Record the starting time\n",
        "        start_time = time.time()\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            raw_state,_ = game.init_game()  # Reset the environment to start a new episode\n",
        "            for player in game.players:\n",
        "                player.stack_reset()\n",
        "\n",
        "            done = False\n",
        "            self.epsilon = (episode+1)**(-1/4)\n",
        "\n",
        "            state_to_update = ()\n",
        "            action_to_update = \"\"\n",
        "            to_update = False\n",
        "            prev_q_table = self.q_table.copy()\n",
        "            episode_reward = 0.0\n",
        "\n",
        "            while not done:\n",
        "                # Print the legal actions\n",
        "\n",
        "                my_player = True if game.get_player_id() == self.my_id else False\n",
        "\n",
        "                if my_player:\n",
        "                    action = self.pick_action(self.get_state(raw_state), raw_state['legal_actions'], self.epsilon)\n",
        "                    state_to_update = self.get_state(raw_state)\n",
        "                    action_to_update = action\n",
        "                else:\n",
        "                    action = adversary.step(raw_state)\n",
        "\n",
        "                raw_next_state, _,bet_round_over = game.step(action)\n",
        "                done = game.round_over()\n",
        "\n",
        "                reward = self.get_reward(game)\n",
        "                episode_reward += reward\n",
        "\n",
        "                if my_player:\n",
        "                    to_update = True if bet_round_over or done else False\n",
        "                else:\n",
        "                    to_update = not to_update\n",
        "\n",
        "                # update Q table\n",
        "                if len(state_to_update) != 0 and to_update:\n",
        "                    my_card = state_to_update[0]\n",
        "                    public_cards = (self.get_state(raw_next_state)[1][0], self.get_state(raw_next_state)[1][1]) if self.get_state(raw_next_state)[1] else None\n",
        "                    next_state = (my_card,public_cards)\n",
        "                    self.update_q_table(state_to_update, action_to_update, reward, next_state)\n",
        "\n",
        "                raw_state = raw_next_state\n",
        "\n",
        "            self.cumulative_rewards.append(episode_reward) if len(self.cumulative_rewards)==0 else self.cumulative_rewards.append(self.cumulative_rewards[-1] + episode_reward)\n",
        "            self.avg_reward.append(self.cumulative_rewards[-1]/len(self.cumulative_rewards))\n",
        "            # Check convergence\n",
        "            max_q_change = np.max(np.abs(self.q_table - prev_q_table))\n",
        "            # To prevent early stage stop due to insufficient information\n",
        "            if max_q_change < threshold and episode >10000:\n",
        "                print(f\"Q-learning converged in {episode+1} episodes\")\n",
        "                break\n",
        "\n",
        "        # Record the ending time\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate the elapsed time\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        # Print the elapsed time in seconds\n",
        "        print(\"Elapsed time In Training: {} seconds\".format(elapsed_time))\n",
        "\n",
        "        # Plot the learning curve\n",
        "        plt.plot(range(1, len(self.cumulative_rewards)+1), self.cumulative_rewards)\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Cumulative Reward Until Convergence\")\n",
        "        plt.title(\"Learning Curve\")\n",
        "        plt.show()\n",
        "        plt.legend()\n",
        "\n",
        "        plt.plot(range(1, len(self.avg_reward)+1), self.avg_reward)\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Average Reward Until Convergence\")\n",
        "        plt.title(\"Average Learning Curve\")\n",
        "        plt.show()\n",
        "        plt.legend()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def print_q_table(self):\n",
        "        print(\"State                | Action               | Q-Value\")\n",
        "        print(\"-----------------------------------------------------\")\n",
        "        i = 0\n",
        "        for state in self.state_space:\n",
        "            s = self.state_space[state]\n",
        "            for a, action in enumerate(self.actions):\n",
        "                # print(state[1])\n",
        "                tmp = str(state)\n",
        "                # if state[0] != \"Terminal\":\n",
        "                i+=1\n",
        "                print(\"{:<20} | {:<20} | {:.2f}\".format(tmp, action, self.q_table[s][a]),flush=True)\n",
        "        # length = len(self.state_space)\n",
        "        # print(f\"Printed: {i}\\nStates: {length} \")\n",
        "\n",
        "\n",
        "    def step(self, raw_state):\n",
        "        state = self.get_state(raw_state)\n",
        "        action = self.pick_action(state,raw_state['legal_actions'], epsilon=0)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def get_reward(self, game):\n",
        "        # Check if it's the final state\n",
        "        if game.round_over():\n",
        "            payoffs = game.get_payoffs()\n",
        "            return payoffs[self.my_id]\n",
        "\n",
        "        # Intermediate states or initial states\n",
        "        else:\n",
        "            return 0"
      ],
      "metadata": {
        "id": "2WayCOO7MqGn"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple_poker_player.py"
      ],
      "metadata": {
        "id": "WTFpoGoeNCvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class PlayerStatus(Enum):\n",
        "    ALIVE = 0\n",
        "    FOLDED = 1\n",
        "    ALLIN = 2\n",
        "\n",
        "class SimplePlayer:\n",
        "\n",
        "    def __init__(self, player_id, np_random, stack=20, name=\"Bot\"):\n",
        "        \"\"\"\n",
        "        Initialize a player.\n",
        "        Args:\n",
        "            player_id (int): The id of the player\n",
        "        \"\"\"\n",
        "        self.np_random = np_random\n",
        "        self.player_id = player_id\n",
        "        self.hand = []\n",
        "        self.init_stack = stack\n",
        "        self.stack = stack\n",
        "        self.name = name\n",
        "        self.status = PlayerStatus.ALIVE\n",
        "\n",
        "        # The chips that this player has put in until now\n",
        "        self.in_chips = 0\n",
        "\n",
        "    def update_in_chips(self, chips_to_add):\n",
        "\n",
        "        if self.stack - self.in_chips - chips_to_add > 0:\n",
        "            self.in_chips += chips_to_add\n",
        "        else:\n",
        "            # print(\"Player is now All-in\")\n",
        "            self.in_chips += self.stack - self.in_chips\n",
        "            self.status = PlayerStatus.ALLIN\n",
        "\n",
        "    def round_reset(self):\n",
        "        self.hand = []\n",
        "        self.status = PlayerStatus.ALIVE\n",
        "        self.in_chips = 0\n",
        "\n",
        "    def stack_reset(self):\n",
        "        self.stack = self.init_stack\n",
        "\n",
        "    def get_state(self, legal_actions, chips, public_cards=None):\n",
        "        \"\"\"\n",
        "        Encode the state for the player\n",
        "\n",
        "        Args:\n",
        "            public_cards (list): A list of public cards that seen by all the players\n",
        "        Returns:\n",
        "            (dict): The state of the player\n",
        "        \"\"\"\n",
        "        dict = {\n",
        "            'hand': [c.get_index() for c in self.hand],\n",
        "            'stack': self.stack,\n",
        "            'all_chips': chips,\n",
        "            'my_chips': self.in_chips,\n",
        "            'legal_actions': legal_actions,\n",
        "        }\n",
        "        if public_cards == None:\n",
        "            dict.update({'public_cards': None})\n",
        "        else:\n",
        "            dict.update({'public_cards': [c.get_index() for c in public_cards]})\n",
        "        return dict\n",
        "\n",
        "    def get_player_id(self):\n",
        "        return self.player_id\n",
        "\n",
        "    def my_name(self):\n",
        "        return self.name"
      ],
      "metadata": {
        "id": "SuOiaVH6M6OS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple_poker_dealer.py"
      ],
      "metadata": {
        "id": "vSyGWYbDNLfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils import Card\n",
        "\n",
        "class SimpleDealer():\n",
        "    def __init__(self, np_random):\n",
        "        self.np_random = np_random\n",
        "        self.deck = self.init_deck()\n",
        "        self.shuffle()\n",
        "        self.pot = 0\n",
        "\n",
        "    def init_deck(self):\n",
        "        suit_list = ['S', 'H', 'D', 'C']\n",
        "        rank_list = ['T', 'J', 'Q', 'K', 'A']\n",
        "        res = [Card(suit, rank) for suit in suit_list for rank in rank_list]\n",
        "        return res\n",
        "\n",
        "    def get_deck(self):\n",
        "        return self.deck\n",
        "\n",
        "    def shuffle(self):\n",
        "        self.np_random.shuffle(self.deck)\n",
        "\n",
        "    def deal_card(self):\n",
        "        \"\"\"\n",
        "        Deal one card from the deck\n",
        "\n",
        "        Returns:\n",
        "            (Card): The drawn card from the deck\n",
        "        \"\"\"\n",
        "        return self.deck.pop()"
      ],
      "metadata": {
        "id": "HCprjBjcNHCE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple_poker_judger.py"
      ],
      "metadata": {
        "id": "DIpYXqgINPDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils import rank2int\n",
        "# from simple_player import PlayerStatus\n",
        "# from simple_player import PlayerStatus\n",
        "\n",
        "class SimpleJudger():\n",
        "\n",
        "    def __init__(self, np_random):\n",
        "        self.np_random = np_random\n",
        "\n",
        "    def judge_game(self, players, public_cards):\n",
        "        ''' Judge the winner of the game.\n",
        "\n",
        "        Args:\n",
        "            players (list): The list of players who play the game\n",
        "            public_card (object): The public card that seen by all the players\n",
        "\n",
        "        Returns:\n",
        "            (list): Each entry of the list corresponds to one entry of the\n",
        "        '''\n",
        "        # Judge who are the winners\n",
        "        winners = [0] * len(players)\n",
        "        self.num_players = len(players)\n",
        "        fold_count = 0\n",
        "        ranks = []\n",
        "\n",
        "        # If every player folds except one, the alive player is the winner\n",
        "        for idx, player in enumerate(players):\n",
        "            ranks.append(rank2int(player.hand[0].rank))\n",
        "            if player.status == PlayerStatus.FOLDED:\n",
        "                fold_count += 1\n",
        "            else:\n",
        "                alive_idx = idx\n",
        "        if fold_count == (self.num_players - 1):\n",
        "            winners[alive_idx] = 1\n",
        "\n",
        "        # If not all folded then\n",
        "        # Check who has the most connections to the board and highest pair\n",
        "        if sum(winners) < 1:\n",
        "            num_pairs = [0] * self.num_players\n",
        "            for idx, player in enumerate(players):\n",
        "                # get the number of connections to the board\n",
        "                for i in range(len(public_cards)):\n",
        "                    if player.hand[0].rank == public_cards[i].rank:\n",
        "                        num_pairs[idx] += 1\n",
        "\n",
        "            # if there is at least one connection to the board\n",
        "            if sum(num_pairs)>0:\n",
        "                max_pair_ids = []\n",
        "                # check who has most pairs\n",
        "                for idx, player in enumerate(players):\n",
        "                    if num_pairs[idx] == max(num_pairs):\n",
        "                        max_pair_ids.append(idx)\n",
        "\n",
        "                # if there is someone with more pairs then he is the winner.\n",
        "                if len(max_pair_ids) == 1:\n",
        "                    winners[max_pair_ids[0]] = 1\n",
        "                else: # else winner is one with greatest rank from those with max pair\n",
        "                    for i in range(len(ranks)):\n",
        "                        if i not in max_pair_ids:\n",
        "                            ranks[i] = ''\n",
        "                    winners = self.get_winners_by_rank(ranks)\n",
        "\n",
        "        # If non of the above conditions, the winner player is the one with the highest card rank\n",
        "        if sum(winners) < 1:\n",
        "            winners = self.get_winners_by_rank(ranks)\n",
        "\n",
        "        # Compute the total chips\n",
        "        total = 0\n",
        "        for p in players:\n",
        "            total += p.in_chips\n",
        "\n",
        "        each_win = float(total) / sum(winners)\n",
        "\n",
        "        payoffs = []\n",
        "        for i, _ in enumerate(players):\n",
        "            if winners[i] == 1:\n",
        "                payoffs.append(each_win - players[i].in_chips)\n",
        "            else:\n",
        "                payoffs.append(float(-players[i].in_chips))\n",
        "        return payoffs\n",
        "\n",
        "    def get_winners_by_rank(self, ranks):\n",
        "        winners = [0] * self.num_players\n",
        "        max_rank = max(ranks)\n",
        "        max_index = [i for i, j in enumerate(ranks) if j == max_rank]\n",
        "        for idx in max_index:\n",
        "            winners[idx] = 1\n",
        "        return winners\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "z0KClEyMNjOL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple_poker_round.py"
      ],
      "metadata": {
        "id": "PeRiGeX-NTD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from simple_player import PlayerStatus\n",
        "\n",
        "class SimpleRound():\n",
        "    \"\"\"Round can call other Classes' functions to keep the game running\"\"\"\n",
        "\n",
        "    def __init__(self, raise_amount, allowed_raise_num, num_players, np_random):\n",
        "        \"\"\"\n",
        "        Initialize the round class\n",
        "\n",
        "        Args:\n",
        "            raise_amount (int): the raise amount for each raise\n",
        "            allowed_raise_num (int): The number of allowed raise num\n",
        "            num_players (int): The number of players\n",
        "        \"\"\"\n",
        "        self.np_random = np_random\n",
        "        self.game_pointer = None\n",
        "        self.raise_amount = raise_amount\n",
        "        self.allowed_raise_num = allowed_raise_num\n",
        "\n",
        "        self.num_players = num_players\n",
        "\n",
        "        # Count the number of raise\n",
        "        self.have_raised = 0\n",
        "\n",
        "        # Count the number without raise\n",
        "        # If every player agree to not raise, the round is over\n",
        "        self.not_raise_num = 0\n",
        "\n",
        "        # Raised amount for each player\n",
        "        self.raised = [0 for _ in range(self.num_players)]\n",
        "        self.player_folded = None\n",
        "        self.have_checked = False\n",
        "\n",
        "    def get_legal_actions(self,players):\n",
        "        \"\"\"\n",
        "        Obtain the legal actions for the current player\n",
        "\n",
        "        Returns:\n",
        "            (list):  A list of legal actions\n",
        "        \"\"\"\n",
        "        all_in_players = [1 if p.status == PlayerStatus.ALLIN else 0 for p in players]\n",
        "        if sum(all_in_players) > 0 :\n",
        "            if players[self.game_pointer].status == PlayerStatus.ALLIN:\n",
        "                return ['check']\n",
        "            else:\n",
        "                if self.raised[self.game_pointer] < max(self.raised):\n",
        "                    return ['fold', 'call']\n",
        "                else:\n",
        "                    return ['check']\n",
        "\n",
        "        full_actions = ['fold', 'check', 'call', 'bet', 'raise']\n",
        "\n",
        "        # If the the number of raises already reaches the maximum number of raises\n",
        "        # or if the player that has raised in not the first, we can not raise any more\n",
        "\n",
        "        if self.have_raised != 0:\n",
        "            full_actions.remove('bet')\n",
        "\n",
        "        # (self.raised[self.game_pointer] < max(self.raised) and self.game_pointer == first_player)\n",
        "        if self.have_raised >= self.allowed_raise_num or self.have_raised == 0 or self.have_checked == True and self.have_raised == 1:\n",
        "            full_actions.remove('raise')\n",
        "\n",
        "        # If the current chips are less than that of the highest one in the round, we can not check\n",
        "        if self.raised[self.game_pointer] < max(self.raised):\n",
        "            full_actions.remove('check')\n",
        "\n",
        "        # If the current player has put in the chips that are more than others, we cannot call\n",
        "        if self.raised[self.game_pointer] == max(self.raised):\n",
        "            full_actions.remove('call')\n",
        "            full_actions.remove('fold')\n",
        "\n",
        "        return full_actions\n",
        "\n",
        "    def start_new_round(self, game_pointer, raised=None):\n",
        "        \"\"\"\n",
        "        Start a new bidding round\n",
        "\n",
        "        Args:\n",
        "            game_pointer (int): The game_pointer that indicates the next player\n",
        "            raised (list): Initialize the chips for each player\n",
        "\n",
        "        Note: For the first round of the game, we need to setup the big/small blind\n",
        "        \"\"\"\n",
        "        self.game_pointer = game_pointer\n",
        "        self.have_raised = 0\n",
        "        self.not_raise_num = 0\n",
        "        self.have_checked = False\n",
        "\n",
        "        if raised:\n",
        "            self.raised = raised\n",
        "        else:\n",
        "            self.raised = [0 for _ in range(self.num_players)]\n",
        "\n",
        "\n",
        "\n",
        "    def proceed_round(self, players, action):\n",
        "        \"\"\"\n",
        "        Call other classes functions to keep one round running\n",
        "\n",
        "        Args:\n",
        "            players (list): The list of players that play the game\n",
        "            action (str): An legal action taken by the player\n",
        "\n",
        "        Returns:\n",
        "            (int): The game_pointer that indicates the next player\n",
        "        \"\"\"\n",
        "        if action not in self.get_legal_actions(players):\n",
        "            raise Exception('{} is not legal action. Legal actions: {}'.format(action, self.get_legal_actions(players)))\n",
        "\n",
        "        if action == 'call':\n",
        "            diff = max(self.raised) - self.raised[self.game_pointer]\n",
        "            self.raised[self.game_pointer] = max(self.raised)\n",
        "            players[self.game_pointer].update_in_chips(diff)\n",
        "            self.not_raise_num += 1\n",
        "\n",
        "        elif action == 'raise' or action == 'bet':\n",
        "            diff = max(self.raised) - self.raised[self.game_pointer] + self.raise_amount\n",
        "            self.raised[self.game_pointer] = max(self.raised) + self.raise_amount\n",
        "            players[self.game_pointer].update_in_chips(diff)\n",
        "            self.have_raised += 1\n",
        "            self.not_raise_num = 1\n",
        "\n",
        "        elif action == 'fold':\n",
        "            players[self.game_pointer].status = PlayerStatus.FOLDED\n",
        "            self.player_folded = True\n",
        "\n",
        "        elif action == 'check':\n",
        "            self.not_raise_num += 1\n",
        "            self.have_checked = True\n",
        "\n",
        "        self.game_pointer = (self.game_pointer + 1) % self.num_players\n",
        "\n",
        "        # Skip the folded players\n",
        "        while players[self.game_pointer].status == PlayerStatus.FOLDED:\n",
        "            self.game_pointer = (self.game_pointer + 1) % self.num_players\n",
        "\n",
        "        return self.game_pointer\n",
        "\n",
        "    def is_over(self):\n",
        "        \"\"\"\n",
        "        Check whether the round is over\n",
        "\n",
        "        Returns:\n",
        "            (boolean): True if the current round is over\n",
        "        \"\"\"\n",
        "        if self.not_raise_num >= self.num_players:\n",
        "            return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "J3Ldm-0nNt0I"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple_poker_game.py"
      ],
      "metadata": {
        "id": "hFFYU6FvNVxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy, copy\n",
        "\n",
        "# from simple_judger import SimpleJudger as Judger\n",
        "# from simple_dealer import SimpleDealer as Dealer\n",
        "# from simple_player import SimplePlayer as Player,PlayerStatus\n",
        "# from simple_round import SimpleRound as Round\n",
        "\n",
        "# Define the simplified poker game\n",
        "class SimplePokerGame():\n",
        "\n",
        "    def __init__(self, allow_step_back=False, num_players=2, p1_name=\"Player_1\",p2_name=\"Player_2\",stacks= 20):\n",
        "\n",
        "        self.allow_step_back = allow_step_back\n",
        "        self.np_random = np.random.RandomState()\n",
        "\n",
        "        self.dealer = SimpleDealer(self.np_random)\n",
        "        self.num_rounds = 2  # Number of betting rounds\n",
        "        self.num_private_cards = 1\n",
        "        self.num_public_cards = 2\n",
        "        self.num_players = num_players\n",
        "        self.game_counter = 0\n",
        "        # Initialize two players to play the game\n",
        "        self.players = [SimplePlayer(0, self.np_random, name=p1_name, stack=stacks),SimplePlayer(1, self.np_random, name=p2_name,stack=stacks)]\n",
        "\n",
        "        # Initialize a judger class which will decide who wins in the end\n",
        "        self.judger = SimpleJudger(self.np_random)\n",
        "        self.first_player = None\n",
        "        # With caution\n",
        "        self.small_blind = 0\n",
        "        self.big_blind = 0\n",
        "        self.ante = 0.5\n",
        "        # self.ante = 0\n",
        "\n",
        "        # Raise amount and allowed times\n",
        "        self.allowed_raise_num = 2\n",
        "        self.raise_amount = 1\n",
        "\n",
        "        # Save betting history\n",
        "        self.history_raise_nums = [0 for _ in range(self.allowed_raise_num)]\n",
        "\n",
        "    def init_game(self):\n",
        "        self.game_counter += 1\n",
        "        for player in self.players:\n",
        "            player.round_reset()\n",
        "       # Initialize a dealer that can deal cards\n",
        "        self.dealer = SimpleDealer(self.np_random)\n",
        "        # Deal cards to each  player to prepare for the first round\n",
        "\n",
        "        for i in range(self.num_private_cards * self.num_players):\n",
        "            self.players[i % self.num_players].hand.append(self.dealer.deal_card())\n",
        "\n",
        "        # Initialize public cards\n",
        "        self.public_cards = []\n",
        "\n",
        "        # Randomly choose a small blind and a big blind(just to keep track of who is playing)\n",
        "        self.player_small = self.np_random.randint(0, self.num_players) if self.game_counter == 1 else (self.player_small + 1) % self.num_players\n",
        "        self.player_big = (self.player_small + 1) % self.num_players\n",
        "        # The player next to the big blind plays the first\n",
        "        self.first_player = self.game_pointer = (self.player_big + 1) % self.num_players\n",
        "\n",
        "        # Both players lose ante\n",
        "        for i in range(self.num_players):\n",
        "            self.players[i].update_in_chips(self.ante)\n",
        "            self.dealer.pot = self.ante\n",
        "\n",
        "        # Initialize a bidding round, in the first round, the big blind and the small blind needs to\n",
        "        # be passed to the round for processing.\n",
        "        self.round = SimpleRound(raise_amount=self.raise_amount,\n",
        "                           allowed_raise_num=self.allowed_raise_num,\n",
        "                           num_players=self.num_players,\n",
        "                           np_random=self.np_random)\n",
        "\n",
        "        self.round.start_new_round(game_pointer=self.game_pointer, raised=[p.in_chips for p in self.players])\n",
        "        # Count the round. There are 2 rounds in each game.\n",
        "        self.round_counter = 0\n",
        "        # Save the history for stepping back to the last state.\n",
        "        self.history = []\n",
        "        state = self.get_state(self.game_pointer)\n",
        "        # Save betting history\n",
        "        self.history_raise_nums = [0 for _ in range(self.allowed_raise_num)]\n",
        "        return state, self.game_pointer\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Get the next state\n",
        "\n",
        "        Args:\n",
        "            action (str): a specific action. (call, raise, fold, or check)\n",
        "\n",
        "        Returns:\n",
        "            (tuple): Tuple containing:\n",
        "\n",
        "                (dict): next player's state\n",
        "                (int): next player id\n",
        "        \"\"\"\n",
        "        if self.allow_step_back:\n",
        "            # First snapshot the current state\n",
        "            r = deepcopy(self.round)\n",
        "            b = self.game_pointer\n",
        "            r_c = self.round_counter\n",
        "            d = deepcopy(self.dealer)\n",
        "            p = deepcopy(self.public_cards)\n",
        "            ps = deepcopy(self.players)\n",
        "            rn = copy(self.history_raise_nums)\n",
        "            self.history.append((r, b, r_c, d, p, ps, rn))\n",
        "\n",
        "        # Then we proceed to the next round\n",
        "        self.game_pointer = self.round.proceed_round(self.players, action)\n",
        "\n",
        "        # Save the current raise num to history\n",
        "        self.history_raise_nums[self.round_counter] = self.round.have_raised\n",
        "\n",
        "\n",
        "        bet_round_over = False\n",
        "        # If a round is over, we deal more public cards\n",
        "        if self.round.is_over():\n",
        "            # For the first round, we deal 2 cards\n",
        "            if self.round_counter == 0:\n",
        "                self.public_cards.append(self.dealer.deal_card())\n",
        "                self.public_cards.append(self.dealer.deal_card())\n",
        "                bet_round_over = True\n",
        "\n",
        "            self.round_counter += 1\n",
        "            self.game_pointer = self.first_player\n",
        "            self.round.start_new_round(self.game_pointer)\n",
        "\n",
        "        state = self.get_state(self.game_pointer)\n",
        "\n",
        "\n",
        "        return state, self.game_pointer , bet_round_over\n",
        "\n",
        "    def step_back(self):\n",
        "        \"\"\"\n",
        "        Return to the previous state of the game\n",
        "\n",
        "        Returns:\n",
        "            (bool): True if the game steps back successfully\n",
        "        \"\"\"\n",
        "        if len(self.history) > 0:\n",
        "            self.round, self.game_pointer, self.round_counter, self.dealer, self.public_cards, \\\n",
        "                self.players, self.history_raises_nums = self.history.pop()\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    def get_legal_actions(self):\n",
        "        \"\"\"\n",
        "        Return the legal actions for current player\n",
        "\n",
        "        Returns:\n",
        "            (list): A list of legal actions\n",
        "        \"\"\"\n",
        "        # pass the player that is to play first\n",
        "        return self.round.get_legal_actions(self.players)\n",
        "\n",
        "    def get_state(self, player):\n",
        "        \"\"\"\n",
        "        Return player's state\n",
        "\n",
        "        Args:\n",
        "            player (int): player id\n",
        "\n",
        "        Returns:\n",
        "            (dict): The state of the player\n",
        "        \"\"\"\n",
        "        self.dealer.pot = np.sum([player.in_chips for player in self.players])\n",
        "\n",
        "        chips = [self.players[i].in_chips for i in range(self.num_players)]\n",
        "        legal_actions = self.get_legal_actions()\n",
        "        state = self.players[player].get_state(legal_actions, chips, self.public_cards)\n",
        "        state['first_player'] = self.first_player\n",
        "        state['round'] = self.round_counter\n",
        "        state['raise_nums'] = self.history_raise_nums\n",
        "        state['pot'] = self.dealer.pot\n",
        "        return state\n",
        "\n",
        "    def get_player_id(self):\n",
        "        \"\"\"\n",
        "        Return the current player's id\n",
        "\n",
        "        Returns:\n",
        "            (int): current player's id\n",
        "        \"\"\"\n",
        "        return self.game_pointer\n",
        "\n",
        "\n",
        "    def get_payoffs(self):\n",
        "        ''' Return the payoffs of the game\n",
        "        Returns:\n",
        "            (list): Each entry corresponds to the payoff of one player\n",
        "        '''\n",
        "        chips_payoffs = self.judger.judge_game(self.players, self.public_cards)\n",
        "        # was big blind but we have set to 0 in case it is used somewhere else\n",
        "        payoffs = np.array(chips_payoffs) / (self.raise_amount)\n",
        "        return payoffs\n",
        "\n",
        "    def update_stack(self,payoffs):\n",
        "        for id ,player in enumerate(self.players):\n",
        "            new_stack = player.stack + payoffs[id]\n",
        "            if new_stack >0:\n",
        "                player.stack += payoffs[id]\n",
        "            else: player.stack = 0\n",
        "\n",
        "\n",
        "    def is_over(self):\n",
        "        \"\"\"\n",
        "        Check if the game is over\n",
        "\n",
        "        Returns:\n",
        "            (boolean): True if the game is over\n",
        "        \"\"\"\n",
        "        lost_players = [1 if p.stack == 0 else 0 for p in self.players]\n",
        "        # If only one player is alive, the game is over.\n",
        "        if sum(lost_players) > 0:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def round_over(self):\n",
        "        \"\"\"\n",
        "        Check if the game round is over\n",
        "\n",
        "        Returns:\n",
        "            (boolean): True if the round is over\n",
        "        \"\"\"\n",
        "        alive_players = [1 if p.status in (PlayerStatus.ALIVE, PlayerStatus.ALLIN) else 0 for p in self.players]\n",
        "        # If only one player is alive, the game is over.\n",
        "        # If all rounds are finished\n",
        "        if self.round_counter >= 2 or sum(alive_players) == 1:\n",
        "            self.update_stack(self.get_payoffs())\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XWqElSpqN2Iz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main.py:\n",
        "Just Press Ctr+F9 To Run all."
      ],
      "metadata": {
        "id": "6741jhORQvSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# from utils import print_card\n",
        "# from simple_poker_game import SimplePokerGame\n",
        "# from random_agent import RandomAgent\n",
        "# from threshold_agent import ThresholdAgent\n",
        "# from policy_iteration import PolicyIterationAgent\n",
        "# from simple_player import PlayerStatus\n",
        "# from q_learning import QLearningAgent\n",
        "# from human_agent import HumanAgent\n",
        "\n",
        "player_types = {0: \"Random Agent\", 1: \"Threshold Loose Agent\", 2: \"Threshold Tight Agent\", 3: \"Policy Iteration Agent\", 4: \"Q-Learning Agent\", 5: \"Human Agent\"}\n",
        "\n",
        "cum_reward_list = []\n",
        "avg_reward_list = []\n",
        "players = []\n",
        "\n",
        "# cummulative_rewards = np.zeros()\n",
        "\n",
        "\"\"\"\n",
        "    Run an experiment and print the results of each round.\n",
        "    Args:\n",
        "        agent: input 0, means Random Agent\n",
        "               input 1, means Threshold Aggresive\n",
        "               input 2, means Threshold Defensive\n",
        "    \"\"\"\n",
        "def print_experiment():\n",
        "    print(\"================= Simple Hold 'em Variation Example =================\")\n",
        "\n",
        "    #-------------------- Choose Opponents -------------------#\n",
        "    print(\"Choose Player One:\")\n",
        "    players_ids = []\n",
        "    while True:\n",
        "        p1 = input(\"0: {:<20} | 1: {:<30} | 2: {:<30} | 3: {:<30}| 4: {:<30} | 5: {:<30}\".format(player_types[0], player_types[1], player_types[2], player_types[3], player_types[4], player_types[5]))\n",
        "\n",
        "        if p1 in ['0', '1', '2', '3', '4', '5']:\n",
        "            p1 = int(p1)\n",
        "            players_ids.append(p1)\n",
        "            break\n",
        "        else: print(\"Invalid Input!\")\n",
        "\n",
        "    print(\"Choose Player Two:\")\n",
        "    while True:\n",
        "        p2 = input(\"0: {:<20} | 1: {:<30} | 2: {:<30} | 3: {:<30}| 4: {:<30} | 5: {:<30}\".format(player_types[0], player_types[1], player_types[2], player_types[3], player_types[4], player_types[5]))\n",
        "        if p2 in ['0', '1', '2', '3', '4', '5']:\n",
        "            p2 = int(p2)\n",
        "            players_ids.append(p2)\n",
        "            break\n",
        "        else: print(\"Invalid Input!\")\n",
        "    print(f\"\\n{player_types[p1]} VS {player_types[p2]}\")\n",
        "    input(\"Press Enter to Start\\n\")\n",
        "\n",
        "    #-------------------- Initialize Opponents -------------------#\n",
        "    for j,i in enumerate(players_ids):\n",
        "        if i == 0:\n",
        "            players.append(RandomAgent())\n",
        "        elif i == 1:\n",
        "            players.append(ThresholdAgent(aggro = True))\n",
        "        elif i == 2:\n",
        "            players.append(ThresholdAgent(aggro = False))\n",
        "        elif i == 3:\n",
        "            players.append(PolicyIterationAgent(adversary=players_ids[(j+1)%2]))\n",
        "        elif i == 4:\n",
        "            players.append(QLearningAgent(id=j))\n",
        "        elif i == 5:\n",
        "            players.append(HumanAgent())\n",
        "\n",
        "\n",
        "    if player_types[p1] != player_types[p2]:\n",
        "        game = SimplePokerGame(p1_name = player_types[p1], p2_name = player_types[p2],stacks= 20)\n",
        "    else:\n",
        "        game = SimplePokerGame(p1_name = \"\" + player_types[p1] + \"_1\", p2_name = \"\" + player_types[p2] + \"_2\",stacks= 20)\n",
        "\n",
        "\n",
        "    # If we have Q-Learning we specify opponent and train\n",
        "    for i,p in enumerate(players):\n",
        "        if p.get_type() == \"Q-Learning Agent\":\n",
        "            print(\"Started Training Q-Learning Agent\")\n",
        "            p.train_agent(game,adversary=players[(i+1)%2])\n",
        "            p.print_q_table()\n",
        "            input(\"Training complete. Press Enter\")\n",
        "\n",
        "\n",
        "    #-------------------- Start Game Loop -------------------#\n",
        "    num_hands_played = 0\n",
        "    game_on = True\n",
        "    while game_on:\n",
        "        # print(\"\\n--------------------------------- Start a new Round ---------------------------------\")\n",
        "        num_hands_played +=1\n",
        "        game = play_round(num_hands_played, game, players)\n",
        "\n",
        "        payoffs = game.get_payoffs()\n",
        "\n",
        "        # Careful problem is policy vs policy are chosen\n",
        "        for id,p in enumerate(players):\n",
        "            if p.get_type() == \"Policy Iteration Agent\" or p.get_type() == \"Q-Learning Agent\" :\n",
        "                update_reward_list(payoffs[id])\n",
        "\n",
        "        # If round over Print Showdown\n",
        "        print_showdown(game,payoffs)\n",
        "\n",
        "        # Check if game is over\n",
        "        if game.is_over():\n",
        "            game_on = False\n",
        "            break\n",
        "        # input('Press Enter to advance to new round!\\n\\n')\n",
        "    # When The game is over print the final winner\n",
        "    print_winner(game)\n",
        "    plot_rewards()\n",
        "\n",
        "def update_reward_list(reward):\n",
        "    cum_reward_list.append(reward) if len(cum_reward_list)==0 else cum_reward_list.append(cum_reward_list[-1] + reward)\n",
        "    avg_reward_list.append(cum_reward_list[-1]/len(cum_reward_list))\n",
        "\n",
        "\n",
        "def plot_rewards():\n",
        "    for p,player in enumerate(players):\n",
        "        if player.get_type() == \"Policy Iteration Agent\":\n",
        "            plt.xlabel(\"Round\")\n",
        "            plt.ylabel(\"Cumulative Reward\")\n",
        "            plt.title(f\"Cumulative Reward for Policy Iteration Agent\")\n",
        "            plt.plot(np.arange(1, len(cum_reward_list)+1), cum_reward_list, label = 'Policy Cumulative Reward')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "            plt.xlabel(\"Round\")\n",
        "            plt.ylabel(\"Average Reward per Round\")\n",
        "            plt.title(f\"Average Reward for Policy Iteration Agent\")\n",
        "            plt.plot(np.arange(1, len(avg_reward_list)+1), avg_reward_list, label = 'Policy Average Reward')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def play_round(round,game,players):\n",
        "    print(f\"\\n\\n============================= Round {round} =============================\")\n",
        "    print(\"\\n================= Public Cards =================\")\n",
        "    print_card([None, None])\n",
        "\n",
        "    # Round starts\n",
        "    state, _ = game.init_game()\n",
        "    print(\"Pot: \", state['pot'],\"\\n\")\n",
        "\n",
        "    public_printed = False\n",
        "    while not game.round_over():\n",
        "\n",
        "        # If not First Round print once the public cards\n",
        "        if state['round']>0 and not public_printed:\n",
        "            print(\"\\n================= Public Cards =================\")\n",
        "            print_card(state['public_cards'])\n",
        "            print(\"Pot: \", state['pot'],\"\\n\")\n",
        "            public_printed = True\n",
        "\n",
        "        # Print the current player's hand\n",
        "        print(\"\\n========= Player: \", game.players[game.game_pointer].my_name(), \" =========\")\n",
        "        # We see only cards of player 0: To simulate being in his side in the table\n",
        "        print(\"Card: \")\n",
        "        print_card(state['hand'] if game.game_pointer == 0 else None)\n",
        "        print(\"Stack at Start: \", state['stack'])\n",
        "        print(\"In Chips: \", state['my_chips'])\n",
        "\n",
        "        if len(state['legal_actions']) > 1: # If Someone not All-In. Action\n",
        "            # input(\"Press enter for adversary to move\")\n",
        "            print(\"Legal actions:\", state['legal_actions'])\n",
        "            action = players[game.get_player_id()].step(state)\n",
        "            print(\"Action chosen:\", action)\n",
        "        else: # Else. Go on untill round finishes\n",
        "            action = state['legal_actions'][0]\n",
        "            print(\"Simulate to end as player is all in\")\n",
        "        # Proced in game\n",
        "        state, _, _ = game.step(action)\n",
        "    return game\n",
        "\n",
        "def print_winner(game):\n",
        "    bankrupt_p = 0\n",
        "    for id, p in enumerate(game.players):\n",
        "        if p.stack == 0:\n",
        "            bankrupt_p = id\n",
        "    print(\"\\n\\nThe Player \", game.players[bankrupt_p].my_name() ,\" Is Bankrupt!\\nTherefore The Winner Is \", game.players[(bankrupt_p+1)%2].my_name())\n",
        "    for p, player in enumerate(players):\n",
        "        if player.get_type() ==\"Policy Iteration Agent\" or player.get_type() ==\"Q-Learning Agent\":\n",
        "            print(\"Average reward at the end of the game for Agent: {:.2f}\".format(avg_reward_list[-1]))\n",
        "\n",
        "\n",
        "    # print(f\"Average Cumulative Reward of player: {game.players[0].my_name()} => {res[0]}\\nAverage Cumulative Reward of player: {game.players[1].my_name()} => {res[1]}\\n\")\n",
        "\n",
        "\n",
        "def print_showdown(game,payoffs):\n",
        "    ''' Get the perfect information of the current state\n",
        "\n",
        "    Returns:\n",
        "        (dict): A dictionary of all the perfect information of the current state\n",
        "    '''\n",
        "\n",
        "    print(\"\\n\\n==================== Showdown =================\")\n",
        "    state = game.get_state(game.get_player_id())\n",
        "    print(\"\\nPublic Cards:\")\n",
        "    if state['public_cards']:\n",
        "        print_card(state['public_cards'])\n",
        "    else: print_card([None ,None])\n",
        "\n",
        "    folded_players = [1 if p.status == PlayerStatus.FOLDED else 0 for p in game.players]\n",
        "    if sum(folded_players) >0:\n",
        "        print(\"Winner due to fold\")\n",
        "\n",
        "    print(\"Player \", game.players[0].my_name(),\" Hand: \")\n",
        "    hand = [c.get_index() for c in game.players[0].hand]\n",
        "    print_card(hand)\n",
        "\n",
        "    print(\"Player \", game.players[1].my_name(),\" Hand: \")\n",
        "    hand = [c.get_index() for c in game.players[1].hand]\n",
        "    print_card(hand)\n",
        "\n",
        "\n",
        "    if np.amax(payoffs) != 0:\n",
        "        max_index = np.argmax(payoffs)  # Find the maximum value\n",
        "        print(\"Player \", game.players[max_index].my_name(), \" wins: \", state['all_chips'][(max_index+1)%2])\n",
        "    else:\n",
        "        print(\"Players Split The Pot: To Each Are Returned: \", state['pot']/2)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Set the number of players\n",
        "    print_experiment()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2b0dXddiQtYU",
        "outputId": "e768b17d-33f3-4002-d5e8-8587a20d75a2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================= Simple Hold 'em Variation Example =================\n",
            "Choose Player One:\n",
            "0: Random Agent         | 1: Threshold Loose Agent          | 2: Threshold Tight Agent          | 3: Policy Iteration Agent        | 4: Q-Learning Agent               | 5: Human Agent                   4\n",
            "Choose Player Two:\n",
            "0: Random Agent         | 1: Threshold Loose Agent          | 2: Threshold Tight Agent          | 3: Policy Iteration Agent        | 4: Q-Learning Agent               | 5: Human Agent                   2\n",
            "\n",
            "Q-Learning Agent VS Threshold Tight Agent\n",
            "Press Enter to Start\n",
            "\n",
            "Started Training Q-Learning Agent\n",
            "Q-learning converged in 18410 episodes\n",
            "Elapsed time In Training: 7.357769727706909 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABphUlEQVR4nO3deXhM59sH8O9Mlskii4gsIhKxxRZLQkQtRYilVa3WWkKVVlGEllRLtUioqlZVqi26RC2lfmonKEprJ7YQRGyJWLLLNvO8f+TNyJhJMpPMZJl8P9eV68o85znn3GcmktuzSoQQAkRERERGQlrRARARERHpE5MbIiIiMipMboiIiMioMLkhIiIio8LkhoiIiIwKkxsiIiIyKkxuiIiIyKgwuSEiIiKjwuSGiIiIjAqTGyKiEqxZswYSiQRxcXEVHQoRaYHJDZGefffdd5BIJPD396/oUCodT09PvPTSSxUdRpV09uxZvPnmm3B3d4dMJoODgwMCAwOxevVqyOXyig6PqFJhckOkZ5GRkfD09MTx48cRGxtb0eGQHowYMQJPnz6Fh4dHhdz/xx9/hJ+fHw4cOIDhw4fju+++w+zZs2FpaYkxY8Zg4cKFFRIXUWVlWtEBEBmTmzdv4ujRo9i8eTPeeecdREZGYs6cOeUag0KhQE5ODiwsLMr1vlVJRkYGrK2tta5vYmICExMTA0ZUtH///RfvvvsuAgICsGPHDtjY2CiPTZkyBSdPnsSFCxf0ci9d3xeiyootN0R6FBkZiZo1a6Jfv354/fXXERkZqTyWm5sLBwcHjB49Wu281NRUWFhYYPr06cqy7OxszJkzBw0bNoRMJoO7uzs+/PBDZGdnq5wrkUgwceJEREZGonnz5pDJZNi1axcAYPHixejYsSNq1aoFS0tL+Pr64o8//lC7/9OnT/H+++/D0dERNjY26N+/P+7evQuJRIJPP/1Upe7du3fx1ltvwdnZGTKZDM2bN8eqVavK8rap+e233+Dr6wtLS0s4ODhgyJAhuH37tkqdw4cP44033kC9evWU78/UqVPx9OlTlXqjRo1CjRo1cP36dfTt2xc2NjYYPnw4gGfv3ZYtW9CiRQvl8xS8fwU0jbkp6GI7cuQI2rdvDwsLC3h5eeGXX35Re57z58+ja9eusLS0RN26dTFv3jysXr1aq3E8c+fOhUQiQWRkpEpiU8DPzw+jRo0CABw8eBASiQQHDx5UqRMXFweJRII1a9aU+L5MnDgRNWrUQGZmptq9hg4dChcXF5VusJ07d6Jz586wtraGjY0N+vXrh4sXLxb7TESGxpYbIj2KjIzEa6+9BnNzcwwdOhQrVqzAiRMn0K5dO5iZmeHVV1/F5s2b8f3338Pc3Fx53pYtW5CdnY0hQ4YAyG996d+/P44cOYJx48ahadOmiI6OxldffYWrV69iy5YtKvfdv38/NmzYgIkTJ8LR0RGenp4AgK+//hr9+/fH8OHDkZOTg3Xr1uGNN97Atm3b0K9fP+X5o0aNwoYNGzBixAh06NABf//9t8rxAomJiejQoYMyKahduzZ27tyJMWPGIDU1FVOmTCnzezh//nx88sknGDRoEN5++20kJSVh2bJl6NKlC86cOQN7e3sAwMaNG5GZmYnx48ejVq1aOH78OJYtW4Y7d+5g48aNKtfMy8tDUFAQOnXqhMWLF8PKykp57MiRI9i8eTPee+892NjY4JtvvsHAgQMRHx+PWrVqFRtrbGwsXn/9dYwZMwbBwcFYtWoVRo0aBV9fXzRv3hxAfjLYrVs3SCQShIaGwtraGj/++CNkMlmJ70VmZiaioqLQpUsX1KtXT8d3smSa3hdPT08sX74c27dvxxtvvKESy19//YVRo0YpW7F+/fVXBAcHIygoCAsXLkRmZiZWrFiBTp064cyZM8qfQ6JyJ4hIL06ePCkAiL179wohhFAoFKJu3bpi8uTJyjq7d+8WAMRff/2lcm7fvn2Fl5eX8vWvv/4qpFKpOHz4sEq9iIgIAUD8888/yjIAQiqViosXL6rFlJmZqfI6JydHtGjRQnTv3l1ZdurUKQFATJkyRaXuqFGjBAAxZ84cZdmYMWOEq6urePjwoUrdIUOGCDs7O7X7Pc/Dw0P069evyONxcXHCxMREzJ8/X6U8OjpamJqaqpRruldYWJiQSCTi1q1byrLg4GABQMycOVOtPgBhbm4uYmNjlWXnzp0TAMSyZcuUZatXrxYAxM2bN1WeBYA4dOiQsuzBgwdCJpOJadOmKcsmTZokJBKJOHPmjLLs0aNHwsHBQe2azyuIpfDPUHEOHDggAIgDBw6olN+8eVMAEKtXr1aWFfW+KBQK4ebmJgYOHKhSvmHDBpXnTUtLE/b29mLs2LEq9RISEoSdnZ1aOVF5YrcUkZ5ERkbC2dkZ3bp1A5Df5TF48GCsW7dO2YzfvXt3ODo6Yv369crznjx5gr1792Lw4MHKso0bN6Jp06bw9vbGw4cPlV/du3cHABw4cEDl3l27dkWzZs3UYrK0tFS5T0pKCjp37ozTp08rywu6YN577z2VcydNmqTyWgiBTZs24eWXX4YQQiWuoKAgpKSkqFy3NDZv3gyFQoFBgwapXN/FxQWNGjVSee7Cz5aRkYGHDx+iY8eOEELgzJkzatceP368xnsGBgaiQYMGytc+Pj6wtbXFjRs3Soy3WbNm6Ny5s/J17dq10aRJE5Vzd+3ahYCAALRu3VpZ5uDgoOwaK05qaioAaOyO0pfn3xeJRII33ngDO3bsQHp6urJ8/fr1cHNzQ6dOnQAAe/fuRXJyMoYOHaryWZmYmMDf31/tZ5SoPLFbikgP5HI51q1bh27duuHmzZvKcn9/f3z55ZeIiopCr169YGpqioEDB2Lt2rXIzs6GTCbD5s2bkZubq5LcXLt2DZcvX0bt2rU13u/Bgwcqr+vXr6+x3rZt2zBv3jycPXtWZayORCJRfn/r1i1IpVK1azRs2FDldVJSEpKTk7Fy5UqsXLlSq7h0de3aNQgh0KhRI43HzczMlN/Hx8dj9uzZ2Lp1K548eaJSLyUlReW1qakp6tatq/Gamrp7atasqXbN0p5769YtBAQEqNV7/v3VxNbWFgCQlpZWYt3SKOp9GTx4MJYuXYqtW7di2LBhSE9Px44dO/DOO+8of3auXbsGAMqEu6jYiSoCkxsiPdi/fz/u37+PdevWYd26dWrHIyMj0atXLwDAkCFD8P3332Pnzp0YMGAANmzYAG9vb7Rq1UpZX6FQoGXLlliyZInG+7m7u6u8LtyKUeDw4cPo378/unTpgu+++w6urq4wMzPD6tWrsXbtWp2fUaFQAADefPNNBAcHa6zj4+Oj83Wfv4dEIsHOnTs1zk6qUaMGgPxksmfPnnj8+DFmzJgBb29vWFtb4+7duxg1apQy1gIymQxSqeaG6qJmQQkhSoy3LOdqo2HDhjA1NUV0dLRW9QsnrYUVtQ5OUe9Lhw4d4OnpiQ0bNmDYsGH466+/8PTpU5UEvOA9/vXXX+Hi4qJ2DVNT/nmhisOfPiI9iIyMhJOTE5YvX652bPPmzfjzzz8REREBS0tLdOnSBa6urli/fj06deqE/fv3Y9asWSrnNGjQAOfOnUOPHj2K/INVkk2bNsHCwgK7d+9WGby6evVqlXoeHh5QKBS4efOmSovJ82v01K5dGzY2NpDL5QgMDCxVTCVp0KABhBCoX78+GjduXGS96OhoXL16FT///DNGjhypLN+7d69B4ioLDw8PjesdabMGkpWVFbp37479+/fj9u3baknt82rWrAkASE5OVim/deuW9gH/v0GDBuHrr79Gamoq1q9fD09PT3To0EF5vKArz8nJyWA/D0SlxTE3RGX09OlTbN68GS+99BJef/11ta+JEyciLS0NW7duBQBIpVK8/vrr+Ouvv/Drr78iLy9P5X/EQP4flrt37+KHH37QeL+MjIwS4zIxMYFEIlH5X3tcXJzaTKugoCAA+SsrF7Zs2TK16w0cOBCbNm3SuK5KUlJSiTGV5LXXXoOJiQnmzp2r1vohhMCjR4+UsRSUFT7+9ddflzkGfQsKCsKxY8dw9uxZZdnjx49Vlgkozpw5cyCEwIgRI1TGwBQ4deoUfv75ZwD5iZSJiQkOHTqkUuf5z1YbgwcPRnZ2Nn7++Wfs2rULgwYNUjkeFBQEW1tbLFiwALm5uWrn6+Pngai02HJDVEZbt25FWloa+vfvr/F4hw4dULt2bURGRiqTmMGDB2PZsmWYM2cOWrZsiaZNm6qcM2LECGzYsAHvvvsuDhw4gBdeeAFyuRxXrlzBhg0bsHv3bvj5+RUbV79+/bBkyRL07t0bw4YNw4MHD7B8+XI0bNgQ58+fV9bz9fXFwIEDsXTpUjx69Eg5Ffzq1asAVLs6wsPDceDAAfj7+2Ps2LFo1qwZHj9+jNOnT2Pfvn14/Phxie9XbGws5s2bp1bepk0b9OvXD/PmzUNoaCji4uIwYMAA2NjY4ObNm/jzzz8xbtw4TJ8+Hd7e3mjQoAGmT5+Ou3fvwtbWFps2bdJqnEx5+/DDD/Hbb7+hZ8+emDRpknIqeL169fD48eMSW+Y6duyI5cuX47333oO3tzdGjBiBRo0aIS0tDQcPHsTWrVuV76ednR3eeOMNLFu2DBKJBA0aNMC2bdtKNRaqbdu2aNiwIWbNmoXs7Gy1BNzW1hYrVqzAiBEj0LZtWwwZMgS1a9dGfHw8tm/fjhdeeAHffvutzvcl0ouKmaRFZDxefvllYWFhITIyMoqsM2rUKGFmZqacQq1QKIS7u7sAIObNm6fxnJycHLFw4ULRvHlzIZPJRM2aNYWvr6+YO3euSElJUdYDICZMmKDxGj/99JNo1KiRkMlkwtvbW6xevVrMmTNHPP9PPyMjQ0yYMEE4ODiIGjVqiAEDBoiYmBgBQISHh6vUTUxMFBMmTBDu7u7CzMxMuLi4iB49eoiVK1eW+F4VTJ/W9DVmzBhlvU2bNolOnToJa2trYW1tLby9vcWECRNETEyMss6lS5dEYGCgqFGjhnB0dBRjx45VTp1+fsqztbW1xniKeu88PDxEcHCw8nVRU8E1TWvv2rWr6Nq1q0rZmTNnROfOnYVMJhN169YVYWFh4ptvvhEAREJCQgnvWr5Tp06JYcOGiTp16ggzMzNRs2ZN0aNHD/Hzzz8LuVyurJeUlCQGDhworKysRM2aNcU777wjLly4oNP7UmDWrFkCgGjYsGGRdQ4cOCCCgoKEnZ2dsLCwEA0aNBCjRo0SJ0+e1Oq5iAxBIoSeRr4RkVE5e/Ys2rRpg99++02racukmylTpuD7779Henp6hW3tQGSsOOaGiNS2LACApUuXQiqVokuXLhUQkXF5/v199OgRfv31V3Tq1ImJDZEBcMwNEWHRokU4deoUunXrBlNTU+zcuRM7d+7EuHHjSpyhQyULCAjAiy++iKZNmyIxMRE//fQTUlNT8cknn1R0aERGid1SRIS9e/di7ty5uHTpEtLT01GvXj2MGDECs2bN4nolevDRRx/hjz/+wJ07dyCRSNC2bVvMmTOHU6iJDITJDRERERkVjrkhIiIio8LkhoiIiIxKtetMVygUuHfvHmxsbEq9rD0RERGVLyEE0tLSUKdOnSL3iitQ7ZKbe/fucfYHERFRFXX79m2Nu9kXVu2SGxsbGwD5b46trW0FR0NERETaSE1Nhbu7u/LveHGqXXJT0BVla2vL5IaIiKiK0WZICQcUExERkVFhckNERERGhckNERERGZVqN+aGiIiIKoZcLkdubm6Rx83NzUuc5q0NJjdERERkUEIIJCQkIDk5udh6UqkU9evXh7m5eZnux+SGiIiIDKogsXFycoKVlZXGGU8Fi+zev38f9erVK9NCu0xuiIiIyGDkcrkysalVq1axdWvXro179+4hLy8PZmZmpb4nBxQTERGRwRSMsbGysiqxbkF3lFwuL9M9mdwQERGRwWnTzaSvPR+Z3BAREZFRqfDkZvny5fD09ISFhQX8/f1x/PjxYusnJydjwoQJcHV1hUwmQ+PGjbFjx45yipaIiIgquwodULx+/XqEhIQgIiIC/v7+WLp0KYKCghATEwMnJye1+jk5OejZsyecnJzwxx9/wM3NDbdu3YK9vX35B09ERESVUoUmN0uWLMHYsWMxevRoAEBERAS2b9+OVatWYebMmWr1V61ahcePH+Po0aPKUdSenp7lGXKxsvPkMJVKYSLVT58hERGRsRBC6KWONiqsWyonJwenTp1CYGDgs2CkUgQGBuLYsWMaz9m6dSsCAgIwYcIEODs7o0WLFliwYEGxo6qzs7ORmpqq8mUIT3Pk8Pl0D/p8fcgg1yciIqqKChojMjMzS6ybk5MDADAxMSnTPSus5ebhw4eQy+VwdnZWKXd2dsaVK1c0nnPjxg3s378fw4cPx44dOxAbG4v33nsPubm5mDNnjsZzwsLCMHfuXL3H/7xzd5KRnafA1cR0g9+LiIioqjAxMYG9vT0ePHgAAMUu4peUlAQrKyuYmpYtPalSi/gpFAo4OTlh5cqVMDExga+vL+7evYsvvviiyOQmNDQUISEhytepqalwd3cvr5CJiIiqPRcXFwBQJjhFkUqlZV6dGKjA5MbR0REmJiZITExUKU9MTFS+Cc9zdXWFmZmZSnNV06ZNkZCQgJycHI17UchkMshkMv0GrwFH2RAREWkmkUjg6uoKJyenctk4s8LG3Jibm8PX1xdRUVHKMoVCgaioKAQEBGg854UXXkBsbCwUCoWy7OrVq3B1dS3zJltlpa+Fh4iIiIyViYkJLCwsivzSR2IDVPA6NyEhIfjhhx/w888/4/Llyxg/fjwyMjKUs6dGjhyJ0NBQZf3x48fj8ePHmDx5Mq5evYrt27djwYIFmDBhQkU9AhEREVUyFTrmZvDgwUhKSsLs2bORkJCA1q1bY9euXcpBxvHx8SpZnLu7O3bv3o2pU6fCx8cHbm5umDx5MmbMmFFRj6DEhhsiIqLKQSL0Nam8ikhNTYWdnR1SUlJga2urt+uejHuM1yPyp7DHhffT23WJiIhIt7/fFb79AhEREZE+MbnRE3ZLERERVQ5MbvSG2Q0REVFlwOSGiIiIjAqTGyIiIjIqTG6IiIjIqDC5ISIiIqPC5IaIiIiMCpMbPeFUcCIiosqByQ0REREZFSY3REREZFSY3BAREZFRYXJDRERERoXJjZ5wPDEREVHlwOSGiIiIjAqTGyIiIjIqTG6IiIjIqDC5ISIiIqPC5IaIiIiMCpMbIiIiMipMboiIiMioMLkhIiIio8LkhoiIiIwKkxsiIiIyKkxuDEAIUdEhEBERVVtMbvREIuHuUkRERJUBkxsiIiIyKkxuiIiIyKgwuSEiIiKjwuSGiIiIjAqTGz0pPJyYk6WIiIgqDpMbIiIiMipMboiIiMioMLkhIiIio8LkhoiIiIwKkxsiIiIyKkxu9KTw7gucLEVERFRxmNwQERGRUWFyQ0REREal1MlNTk4OYmJikJeXp894iIiIiMpE5+QmMzMTY8aMgZWVFZo3b474+HgAwKRJkxAeHq73AImIiIh0oXNyExoainPnzuHgwYOwsLBQlgcGBmL9+vWlCmL58uXw9PSEhYUF/P39cfz48SLrrlmzBhKJROWrcByVgeD+C0RERBXGVNcTtmzZgvXr16NDhw6QFJoi1Lx5c1y/fl3nANavX4+QkBBERETA398fS5cuRVBQEGJiYuDk5KTxHFtbW8TExChfF46jokhQ8TEQERFRKVpukpKSNCYdGRkZpUoylixZgrFjx2L06NFo1qwZIiIiYGVlhVWrVhV5jkQigYuLi/LL2dlZ5/sSERGRcdI5ufHz88P27duVrwsSmh9//BEBAQE6XSsnJwenTp1CYGDgs4CkUgQGBuLYsWNFnpeeng4PDw+4u7vjlVdewcWLF4usm52djdTUVJUvQ7j5KMMg1yUiIiLd6NwttWDBAvTp0weXLl1CXl4evv76a1y6dAlHjx7F33//rdO1Hj58CLlcrtby4uzsjCtXrmg8p0mTJli1ahV8fHyQkpKCxYsXo2PHjrh48SLq1q2rVj8sLAxz587VKa7SeJKRY/B7EBERUcl0brnp1KkTzp49i7y8PLRs2RJ79uyBk5MTjh07Bl9fX0PEqCIgIAAjR45E69at0bVrV2zevBm1a9fG999/r7F+aGgoUlJSlF+3b982eIxERERUcXRuuQGABg0a4IcffijzzR0dHWFiYoLExESV8sTERLi4uGh1DTMzM7Rp0waxsbEaj8tkMshksjLHWhJuv0BERFQ56Nxys2PHDuzevVutfPfu3di5c6dO1zI3N4evry+ioqKUZQqFAlFRUVqP35HL5YiOjoarq6tO9yYiIiLjpHNyM3PmTMjlcrVyIQRmzpypcwAhISH44Ycf8PPPP+Py5csYP348MjIyMHr0aADAyJEjERoaqqz/2WefYc+ePbhx4wZOnz6NN998E7du3cLbb7+t872JiIjI+OjcLXXt2jU0a9ZMrdzb27vIrqHiDB48GElJSZg9ezYSEhLQunVr7Nq1SznIOD4+HlLpsxzsyZMnGDt2LBISElCzZk34+vri6NGjGmMiIiKi6kfn5MbOzg43btyAp6enSnlsbCysra1LFcTEiRMxceJEjccOHjyo8vqrr77CV199Var7EBERkfHTuVvqlVdewZQpU1RWI46NjcW0adPQv39/vQZHREREpCudk5tFixbB2toa3t7eqF+/PurXr4+mTZuiVq1aWLx4sSFirBIKr83MraWIiIgqTqm6pY4ePYq9e/fi3LlzsLS0hI+PD7p06WKI+IiIiIh0Uqp1biQSCXr16oVevXrpOx4iIiKiMilVchMVFYWoqCg8ePAACoVC5VhxG14SERERGZrOyc3cuXPx2Wefwc/PD66urqXaCZyIiIjIUHRObiIiIrBmzRqMGDHCEPEQERERlYnOs6VycnLQsWNHQ8RStRVqwRLcXYqIiKjC6JzcvP3221i7dq0hYiEiIiIqM527pbKysrBy5Urs27cPPj4+MDMzUzm+ZMkSvQVHREREpCudk5vz58+jdevWAIALFy6oHOPgYiIiIqpoOic3Bw4cMEQcRERERHqh85ibArGxsdi9ezeePn0KABDVfM8Bbr9ARERUOeic3Dx69Ag9evRA48aN0bdvX9y/fx8AMGbMGEybNk3vAVYV7JEjIiKqHHRObqZOnQozMzPEx8fDyspKWT548GDs2rVLr8ERERER6UrnMTd79uzB7t27UbduXZXyRo0a4datW3oLjIiIiKg0dG65ycjIUGmxKfD48WPIZDK9BEVERERUWjonN507d8Yvv/yifC2RSKBQKLBo0SJ069ZNr8ERERER6UrnbqlFixahR48eOHnyJHJycvDhhx/i4sWLePz4Mf755x9DxFglSMARxURERJWBzi03LVq0wNWrV9GpUye88soryMjIwGuvvYYzZ86gQYMGhoixSuB+UkRERJWDzi03AGBnZ4dZs2bpOxYiIiKiMivV9guaSCQSWFhYoF69ehxYTERERBVG5+SmdevWyj2kClYlLrynlJmZGQYPHozvv/8eFhYWegqTiIiISDs6j7n5888/0ahRI6xcuRLnzp3DuXPnsHLlSjRp0gRr167FTz/9hP379+Pjjz82RLyVFgcUExERVQ46t9zMnz8fX3/9NYKCgpRlLVu2RN26dfHJJ5/g+PHjsLa2xrRp07B48WK9BltVcG8pIiKiiqNzy010dDQ8PDzUyj08PBAdHQ0gv+uqYM8pIiIiovKkc3Lj7e2N8PBw5OTkKMtyc3MRHh4Ob29vAMDdu3fh7OysvyiJiIiItKRzt9Ty5cvRv39/1K1bFz4+PgDyW3Pkcjm2bdsGALhx4wbee+89/UZKREREpAWdk5uOHTvi5s2biIyMxNWrVwEAb7zxBoYNGwYbGxsAwIgRI/QbJREREZGWdEpucnNz4e3tjW3btuHdd981VExVkoSTpYiIiCoFncbcmJmZISsry1CxGA1uxUBERFRxdB5QPGHCBCxcuBB5eXmGiIeIiIioTHQec3PixAlERUVhz549aNmyJaytrVWOb968WW/BEREREelK5+TG3t4eAwcONEQsVRqH3BAREVUOOic3q1evNkQcRERERHqh85gbAMjLy8O+ffvw/fffIy0tDQBw7949pKen6zW4qqTwbCluv0BERFRxdG65uXXrFnr37o34+HhkZ2ejZ8+esLGxwcKFC5GdnY2IiAhDxElERESkFZ1bbiZPngw/Pz88efIElpaWyvJXX30VUVFReg2OiIiISFc6t9wcPnwYR48ehbm5uUq5p6cn7t69q7fAiIiIiEpD55YbhUIBuVyuVn7nzh3l9gtEREREFUXn5KZXr15YunSp8rVEIkF6ejrmzJmDvn376jO2KkXCyeBERESVgs7dUl9++SWCgoLQrFkzZGVlYdiwYbh27RocHR3x+++/GyLGKoeTpYiIiCqOzi03devWxblz5/DRRx9h6tSpaNOmDcLDw3HmzBk4OTmVKojly5fD09MTFhYW8Pf3x/Hjx7U6b926dZBIJBgwYECp7ktERETGR+eWm6ysLFhYWODNN9/USwDr169HSEgIIiIi4O/vj6VLlyIoKAgxMTHFJktxcXGYPn06OnfurJc4iIiIyDjo3HLj5OSE4OBg7N27FwqFoswBLFmyBGPHjsXo0aPRrFkzREREwMrKCqtWrSryHLlcjuHDh2Pu3Lnw8vIqcwxERERkPHRObn7++WdkZmbilVdegZubG6ZMmYKTJ0+W6uY5OTk4deoUAgMDnwUklSIwMBDHjh0r8rzPPvsMTk5OGDNmTIn3yM7ORmpqqsoXERERGS+dk5tXX30VGzduRGJiIhYsWIBLly6hQ4cOaNy4MT777DOdrvXw4UPI5XI4OzurlDs7OyMhIUHjOUeOHMFPP/2EH374Qat7hIWFwc7OTvnl7u6uU4xERERUtZRqbykAsLGxwejRo7Fnzx6cP38e1tbWmDt3rj5jU5OWloYRI0bghx9+gKOjo1bnhIaGIiUlRfl1+/Ztg8YIAIKbSxEREVUYnQcUF8jKysLWrVuxdu1a7Nq1C87Ozvjggw90uoajoyNMTEyQmJioUp6YmAgXFxe1+tevX0dcXBxefvllZVnBuB9TU1PExMSgQYMGKufIZDLIZDKd4iIiIqKqS+fkZvfu3Vi7di22bNkCU1NTvP7669izZw+6dOmi883Nzc3h6+uLqKgo5XRuhUKBqKgoTJw4Ua2+t7c3oqOjVco+/vhjpKWl4euvv2aXExEREeme3Lz66qt46aWX8Msvv6Bv374wMzMrUwAhISEIDg6Gn58f2rdvj6VLlyIjIwOjR48GAIwcORJubm4ICwuDhYUFWrRooXK+vb09AKiVExERUfWkc3KTmJio1z2kBg8ejKSkJMyePRsJCQlo3bq1spsLAOLj4yGVlnpoEBEREVUzElGK0a8KhQKxsbF48OCB2lo3pemeKk+pqamws7NDSkoKbG1t9XbdDSdv48M/zgMAoj/tBRuLsrVoERER0TO6/P3WueXm33//xbBhw3Dr1i21WUESiUTjjuHVDedKERERVRydk5t3330Xfn5+2L59O1xdXSGRcDdsANwTnIiIqJLQObm5du0a/vjjDzRs2NAQ8RARERGVic4jdf39/REbG2uIWIiIiIjKTOeWm0mTJmHatGlISEhAy5Yt1aaC+/j46C24qoTdc0RERJWDzsnNwIEDAQBvvfWWskwikUAIwQHF/4+7LxAREVUcnZObmzdvGiIOIiIiIr3QObnx8PAwRBxEREREelGqjTOvX7+OpUuX4vLlywCAZs2aYfLkyWqbVhIRERGVN51nS+3evRvNmjXD8ePH4ePjAx8fH/z3339o3rw59u7da4gYiYiIiLSmc8vNzJkzMXXqVISHh6uVz5gxAz179tRbcFUJ50oRERFVDjq33Fy+fBljxoxRK3/rrbdw6dIlvQRV5XG2FBERUYXRObmpXbs2zp49q1Z+9uxZODk56SMmIiIiolLTuVtq7NixGDduHG7cuIGOHTsCAP755x8sXLgQISEheg+QiIiISBc6JzeffPIJbGxs8OWXXyI0NBQAUKdOHXz66ad4//339R4gERERkS50Tm4kEgmmTp2KqVOnIi0tDQBgY2Oj98CqGu6+QEREVDloPebm6dOn2Lp1qzKhAfKTGhsbG6SmpmLr1q3Izs42SJBERERE2tI6uVm5ciW+/vprja00tra2+Oabb/Djjz/qNbiqSnC6FBERUYXROrmJjIzElClTijw+ZcoU/Pzzz/qIiYiIiKjUtE5url27hlatWhV53MfHB9euXdNLUFURdwInIiKqHLRObvLy8pCUlFTk8aSkJOTl5eklqKqIA4qJiIgqB62Tm+bNm2Pfvn1FHt+zZw+aN2+ul6CqIiY3RERElYPWyc1bb72Fzz//HNu2bVM79tdff2H+/Pl466239BocERERka60Xudm3LhxOHToEPr37w9vb280adIEAHDlyhVcvXoVgwYNwrhx4wwWaFXC8TdEREQVR6e9pX777TesW7cOjRs3xtWrVxETE4MmTZrg999/x++//26oGImIiIi0pvMKxYMGDcKgQYMMEQsRERFRmem8KzgRERFRZcbkRk8k4HQpIiKiyoDJjQFwPDEREVHFYXJDRERERoXJDRERERkVrWZLvfbaa1pfcPPmzaUOhoiIiKistEpu7OzsDB1HlcftF4iIiCoHrZKb1atXGzoOIiIiIr3gmBsDeJorx//O3kVyZk5Fh0JERFTtaNVy07ZtW0RFRaFmzZpo06YNJMX0wZw+fVpvwVVVc7dexJ5LiWjlbo//TXihosMhIiKqVrRKbl555RXIZDLl98UlNwTsuZQIADh3O7liAyEiIqqGtEpu5syZo/z+008/NVQsRERERGWm85gbLy8vPHr0SK08OTkZXl5eegmKiIiIqLR0Tm7i4uIgl8vVyrOzs3Hnzh29BEVERERUWlp1SwHA1q1bld/v3r1bZe0buVyOqKgo1K9fX7/REREREelI6+RmwIABAACJRILg4GCVY2ZmZvD09MSXX35ZqiCWL1+OL774AgkJCWjVqhWWLVuG9u3ba6y7efNmLFiwALGxscjNzUWjRo0wbdo0jBgxolT31hcOsiYiIqoctE5uFAoFAKB+/fo4ceIEHB0d9RLA+vXrERISgoiICPj7+2Pp0qUICgpCTEwMnJyc1Oo7ODhg1qxZ8Pb2hrm5ObZt24bRo0fDyckJQUFBeomJiIiIqi6JEEJUZAD+/v5o164dvv32WwD5SZS7uzsmTZqEmTNnanWNtm3bol+/fvj8889LrJuamgo7OzukpKTA1ta2TLEXtvXcPbz/+xm18rjwfnq7BxERUXWly99vrVtuCouKikJUVBQePHigbNEpsGrVKq2vk5OTg1OnTiE0NFRZJpVKERgYiGPHjpV4vhAC+/fvR0xMDBYuXKixTnZ2NrKzs5WvU1NTtY6PiIiIqh6dk5u5c+fis88+g5+fH1xdXcs01uThw4eQy+VwdnZWKXd2dsaVK1eKPC8lJQVubm7Izs6GiYkJvvvuO/Ts2VNj3bCwMMydO7fUMWqrghvAiIiI6P/pnNxERERgzZo1FTqA18bGBmfPnkV6ejqioqIQEhICLy8vvPjii2p1Q0NDERISonydmpoKd3f3coyWiIiIypPOyU1OTg46duyol5s7OjrCxMQEiYmJKuWJiYlwcXEp8jypVIqGDRsCAFq3bo3Lly8jLCxMY3Ijk8mUW0cQERGR8dN5Eb+3334ba9eu1cvNzc3N4evri6ioKGWZQqFAVFQUAgICtL6OQqFQGVdDRERE1ZfOLTdZWVlYuXIl9u3bBx8fH5iZmakcX7JkiU7XCwkJQXBwMPz8/NC+fXssXboUGRkZGD16NABg5MiRcHNzQ1hYGID8MTR+fn5o0KABsrOzsWPHDvz6669YsWKFro9CRERERkjn5Ob8+fNo3bo1AODChQsqx0ozuHjw4MFISkrC7NmzkZCQgNatW2PXrl3KQcbx8fGQSp81MGVkZOC9997DnTt3YGlpCW9vb/z2228YPHiwzvcmIiIi41Ph69yUN0Otc/O/s3cxed1ZtXKuc0NERFR2uvz91nnMDREREVFlpnW3VJs2bTR2O9nZ2aFx48aYPHkymjVrptfgiIiIiHSl88aZz0tOTsbp06fRpk0b7N+/Hy+88IK+YiMiIiLSmdbJzZw5c4o9PmvWLMyePVtlWjcRERFRedPbmJthw4YhOjpaX5cjIiIiKhW9JTcmJiZqm2gSERERlTe9JTebN2/mgGIiIiKqcFqPufnmm280lqekpODUqVPYvn07du7cqbfAiIiIiEpD6+Tmq6++0lhua2uLJk2a4NChQzrtB0VERERkCFonNzdv3jRkHFVeabaeICIiIv3jCsVERERkVJjcEBERkVFhckNERERGhckNERERGRUmN0RERGRUtJotdf78ea0v6OPjU+pgiIiIiMpKq+SmdevWkEgkEEKUOOVZLpfrJTAiIiKi0tCqW+rmzZu4ceMGbt68iU2bNqF+/fr47rvvcObMGZw5cwbfffcdGjRogE2bNhk6XiIiIqJiadVy4+Hhofz+jTfewDfffIO+ffsqy3x8fODu7o5PPvkEAwYM0HuQRERERNrSeUBxdHQ06tevr1Zev359XLp0SS9BVUVCiIoOgYiIiFCK5KZp06YICwtDTk6OsiwnJwdhYWFo2rSpXoMjIiIi0pXWe0sViIiIwMsvv4y6desqZ0adP38eEokEf/31l94DJCIiItKFzslN+/btcePGDURGRuLKlSsAgMGDB2PYsGGwtrbWe4BEREREutApucnNzYW3tze2bduGcePGGSomIiIiolLTacyNmZkZsrKyDBULERERUZnpPKB4woQJWLhwIfLy8gwRDxEREVGZ6Dzm5sSJE4iKisKePXvQsmVLtXE2mzdv1ltwRERERLrSObmxt7fHwIEDDRELERERVRFCCGTmyGEty08l8uQK9PrqEG48zMD8V1tguL9HCVcwHJ2Tm9WrVxsiDiIiIqoiUrNy4fPpniKPz/rzAl5t4wYrc53TDL2omLsSERFRlXLxXgreWnMCianZJdaNfNu/whIboJTJzR9//IENGzYgPj5eZaViADh9+rReAqtqStotnYiIqKq59SgDXb84qFVdj1pWmD+gJTo1cjRsUFrQObn55ptvMGvWLIwaNQr/+9//MHr0aFy/fh0nTpzAhAkTDBEjERERlZOM7DwM+v4YLt5LLbJO8zq2WD6sLTwdK+fivTonN9999x1WrlyJoUOHYs2aNfjwww/h5eWF2bNn4/Hjx4aIkYiIiAxMoRC4nJCKft8c0XjcxsIUf3/QDQ7W5uUcme50Tm7i4+PRsWNHAIClpSXS0tIAACNGjECHDh3w7bff6jdCIiIi0ousXDnCd16BQgjcT8lCz2bOeJCahcV7rhZ5zp6pXdDY2aYcoyw7nZMbFxcXPH78GB4eHqhXrx7+/fdftGrVCjdv3oQQwhAxEhERURk8zZGj6exdauV7LyVqrP/rmPbo3Ki2ocMyGJ2Tm+7du2Pr1q1o06YNRo8ejalTp+KPP/7AyZMn8dprrxkiRiIiItKBXCEQ9ygDi3fHYOeFBK3P+22MP9rXd4C5qc4bGFQqOic3K1euhEKhAJC/FUOtWrVw9OhR9O/fH++8847eAyQiIqKS5coVOHr9EfZdSsSv/94qst65Ob1gYSaFqVSKv87dg5mJFH1buhjVrF+dkxupVAqp9FlGN2TIEAwZMkSvQREREZEqhUJAInm29EhWrhydFu7Hw/ScEs7M99fETmhZ106lbEAbN73HWRnonNx06dIFL774Irp27YoXXngBFhYWhoiLiIjIKOXJFTA1kSq/N5FKlAlLdp4c/zt7Dx/+cV5Zv7aNDIFNnfH78Xit71HL2hy9W7ggtG9T1JBVv/V6dX7iXr164dChQ1iyZAny8vLg5+enkuxYWVkZIk4iIqIq6UpCKsJ3XsHBmKRSnZ+Ulq11YhPgVQuTAxuhg1etUt3LWOic3Hz88ccAgLy8PJw4cQJ///03Dh48iEWLFkEqlSIrK0vvQRIREVU18Y8y0eWLAwa7vq2FKSLf7qDW1URl2Fvqxo0biI6Oxrlz53D+/HnY2NigS5cu+oyNiIhIrx6lZ8PK3BSW5ibwnLkdAGAjM0XUtK6wtTSDhZmJxvNy8hS4+TADjZ1rqA28Tc/Ow4TI0/j7aulaZgqrITPF0dDusDIzUXZdnb+TjHoOVrC3yl88TwhhVIN/DUHn5GbYsGH4+++/kZ2djS5duqBr166YOXMmfHx8Sv1mL1++HF988QUSEhLQqlUrLFu2DO3bt9dY94cffsAvv/yCCxcuAAB8fX2xYMGCIusTEZFxeJKRAztLMwBAjlyBP8/cRejmaDSobY3bj58iR67AlMBGGBngqbKK7sP0bPgviIJcoXkttrTsPLRfEKVWbiqVIK+Ic3S1flwH+NS1h6W55uSpOD517VVeM7Epmc7Jzbp16+Do6Ii3334b3bt3R6dOnco0zmb9+vUICQlBREQE/P39sXTpUgQFBSEmJgZOTk5q9Q8ePIihQ4eiY8eOsLCwwMKFC9GrVy9cvHgRbm7GOeqbiKi623DiNj7cdF7jsetJGcrvl+67hqX7runlnvpIbA590A31anEsanmTCB2XFX7y5AkOHz6MgwcP4u+//8bly5fRunVrvPjii3jxxRfRq1cvnQLw9/dHu3btlNs2KBQKuLu7Y9KkSZg5c2aJ58vlctSsWRPffvstRo4cWWL91NRU2NnZISUlBba2tjrFWpyt5+7h/d/PqJXHhffT2z2IiKqLjOw8mJlI8SQzB/4aWlX0oZ+PK74d2gY7LyTgx8M3cDo+udTX2jS+I9rWs2erigHp8vdb55abmjVron///ujfvz8AIDY2FvPmzcMXX3yBhQsXQi6Xa32tnJwcnDp1CqGhocoyqVSKwMBAHDt2TKtrZGZmIjc3Fw4ODhqPZ2dnIzs7W/k6NbXoXU7Loqgc8UFaFpxsOF2eiKgkl+6lou83h4utU8/BCn6eNbH59F2M6+KF0D7eyM5TICtXnr8Y3TeHcetRptp5m8YHwNdD89+Jvi1d0belq1q5QiEglaomK3KFgBACpiZSJKZmwcrcBDYWZjo8JZUHnZObR48eKWdIHTx4EJcuXYK9vT1efvlldO3aVadrPXz4EHK5HM7Ozirlzs7OuHLlilbXmDFjBurUqYPAwECNx8PCwjB37lyd4tKnY9cf4ZXW7C4jIgLyx79cvJeKM/FPMKC1G+4mP8UHG8/hXkrJM21vLOirTDaWDGqtLLcwM1EOBP77g27IypUXOTBYF88nNgBgIpUAyC93tuV/XCsrnZMbJycnODo6onPnzhg7dixefPFFtGzZ0hCxlSg8PBzr1q3DwYMHi1xMMDQ0FCEhIcrXqampcHd3L68QMXndWSY3RFTtJKRkocsXB5CTpyiyjjZjY1q62SHstZZo4ab9dGd9JDZUtemc3Jw/fx7NmzfXy80dHR1hYmKCxETVXUkTExPh4uJS7LmLFy9GeHg49u3bBx8fnyLryWQyyGQyvcRLRETFO3s7GQOW/1Pq8w9OfxGejtZ6jIiqI52Tm+bNmyMvLw8HDx7E9evXMWzYMNjY2ODevXuwtbVFjRo1tL6Wubk5fH19ERUVhQEDBgDIH1AcFRWFiRMnFnneokWLMH/+fOzevRt+fn66PgIRkdEqWM5/48k7eNG7NpLSsvEgLRvdmjjhYXo2/ObtAwD0bemC4zefICqkK+ysNI8ZKVhPJTMnf3CvmYnmnaKzcuXo+/Vh3HiYofF4cV73rYtPXmqmnOJNpA86Jze3bt1C7969ER8fj+zsbPTs2RM2NjZYuHAhsrOzERERodP1QkJCEBwcDD8/P7Rv3x5Lly5FRkYGRo8eDQAYOXIk3NzcEBYWBgBYuHAhZs+ejbVr18LT0xMJCflbudeoUUOnxErfOEKeiCraX+fuYZKGWZua7IjO/93Z6rM9AAA3e0sc/rAbjsQ+RMiGc3iYnq12jrOtDHum5CdDmTl5aPPZXmQX0+204Z0AtHK3g8zUhAvPUbnSObmZPHky/Pz8cO7cOdSq9WzvildffRVjx47VOYDBgwcjKSkJs2fPRkJCAlq3bo1du3YpBxnHx8er7EK+YsUK5OTk4PXXX1e5zpw5c/Dpp5/qfH8ioqps14X7ePe302W+zt3kp/D6aEexdRJTs5XJUHGOzuyOOvaWKmVMbKg86ZzcHD58GEePHoW5ublKuaenJ+7evVuqICZOnFhkN9TBgwdVXsfFxZXqHkRExiQrVw7vT3YVebxgdd0aMlOkZ+cpywf7ueOTl5vhRNxjxD/KxJytF/USz/gXG2BGb2+9XIuorHRObhQKhca1bO7cuQMbGxu9BEVUWlm5cmTnKoocQ0BkDLLzik5sdk/pgiYu6r+Lbz7MgKudhXImUbcm+SvAjwzwwJ0nT9F5Uf4Gj3aWZtg2qRPcHdRX1Z2y7gy2nL2nfB3axxvBHT0hM5WyZYYqFZ2Tm169emHp0qVYuXIlgPymxvT0dMyZMwd9+/bVe4BE2kpKy0a7+fmDJYv6BU9UHnZfTMA7v55Svm7oVAOmUgmuJKTBztIM/33Uo1TTlU/EPcYbEeoLnJ75pCdqWptrOOOZ+kXMQJJIJHB3sNJqNfWlQ9pgyaDWSMvK438gqFLTefuFO3fuICgoCEIIXLt2DX5+frh27RocHR1x6NAhjftBVSblvf0CwC0YykvBDr8F+L5TRdB2UO/q0e2UrSdA/iwn0+dmI2XlyjH8x/9w6taTIq9zdV4fmJtqnsVEZEwMuv1C3bp1ce7cOaxfvx7nzp1Deno6xowZg+HDh8PS0rLkCxAZwOOMHLWyhJQsuNhxBVHSP7lC4PydZNhYmKGhUw1k58mx/sRtzP6f9uNXRq8+UaYYvF1ssGtKlzJdg8hY6ZzcAICpqSmGDx+O4cOHK8vu37+PDz74QLkBJlF5+uVYnFrZtvP38HZnr/IPhozawZgHGKVFYrJ6VDv4edaEmYkU3x2IhQAwtH09dAzfX6b7H5nRDXVrcpdpouLolNxcvHgRBw4cgLm5OQYNGgR7e3s8fPgQ8+fPR0REBLy8+IeEKoamZdyPXn/E5Ib0RgiBF8L3a7UH0tnZPWFv9WwMTEivJsrv48L74WTcY7yuYeyMJt29nbByhC9MpBIO2iXSktbJzdatW/H6668jLy9/SuGiRYvwww8/YNCgQfD19cWff/6J3r17GyxQoqJE30lRfj/cvx7uPHmKv68mIU+h03AyIo3Cdl7G93/fKLGeV21r/PJWe61aVfw8HRAX3g/ZeXI8ychV6T5Nz87DoatJ8PWoyY0ZiUpJ6+Rm3rx5mDBhAj7//HP8+OOPCAkJwfvvv48dO3agXbt2hoyRtFRdVwB9+dsjyu8/CGqCPRcT8ffVJBy6mlSBUVFlk50nx42kDDzOyIFEAng51sCuC/fx6V+XADwbgC6EwL2ULDxIzUJqVp7GxOadLl4I7du0zDHJTE3gYqc6a6qGzBR9W7qW+dpE1ZnWyU1MTAzWrl2LGjVqYNKkSZg+fTq++uorJjaVxEd/RmPtf/Ho5+OK5cPaVnQ4BpeTp4C5qRTv/HpSpdzeyhxS6bME72mOHJbm3CG4unt+Jl1p6wDAlc97c9dpokpO6+QmLS1NOfXKxMQElpaWHGNTiaz9Lx4AsP38fSwfVr73PnXrMQauOAZzUynWvu0PP08HtTphOy7j+0M3MLFbQ0wPaqLhKto5EfcYI386jqe56gtJTglsBADo08IF0zeeAwD8ePgGJvVoVOr7UdWWmpULn09L3i6gJL+81R4t3OzgUMJaMkRUOeg0oHj37t2ws7MD8Gz37gsXLqjU6d+/v/6iI63cTX6q8ro8u6cUCoGBK/IHRubkKfB6xDG4O1ji8IfdlXWuJKTi+0P5TfvfHojVKbnJzMnDzugE9GjqhI/+jFZu9qfJ5P9PYqxlz36sv9x7FZN6NEJWrhxbztzFQN+6Re5sTFXL7ceZ6LzoABxryHDy40C89t0/aOJii7DXWiInT4HYB+no+83hEq/zcb+mmLf9cpHHlw9riy6Na+szdCIyMJ2Sm+DgYJXX77zzjspriUSicWsGMqx1x+NVXtcP3YGD01+EZxErkqZl5eJ+ShZsLczKvA7Mtuj7amW3Hz9VrjHzIC0LvZeq/oFpNnsXMnPkqGVtjp1TOsPJpugYWn66B3ItBgYfn9WjyIQuT65QLlU/c3M0F/czAtvP38eEtfmbRT5Mz1Z2KZ2OT8bvz/17KHD5s95FdlH61LVH1OVEBHf0VNvwkYiqHq3/C6tQKEr8YmJTMZbtj1Ure3HxQeX3ey4m4KM/o5GTp8DTHDlafroHvb46hA5hUXjtu3/KdO+iVmXuEBYFADh89aHascyc/J+TRxk5aD8/qsjkJfK/W1olNuO6eKklSDsnd1Z+v/tiosqxPLmixGvqU4cFUfCcuR2pWbnlet+q6H7KU2QV6nIsvIB6alYu1p+Ih+fM7crERltx4f2KHXvVvr4DQvs2ZWJDZCRKtYgfVS6BTZ2x73KiWnlyZg7srcwx7v/3uHG0NkdgM2eVOqfjk+E5czt6NXOGraUZwl9rqbYEfFGiNNyzsKc5ckz7/7EvxWnw0Q5M6NYAq/+JQ/SnQTCRSiCEwKw/L2is//krzTGonTtuJGWgvqO1xsGd3oX2lXr+D+GNhxlo7Fw++07FPcxAQmr+uig+n+7Btfl9DNotdi/5qXKROF+Pmtg0vqPB7qVP/954hCEr/9X5vIZONRD7IB0AUNtGhqS0bPVrh/Yoc3xEVLUwuamCcuUK/HHqDjo3ckTdmlZo7W6nMblp/dlenJgVqHz9zf5YvOitee+vPZfyz7c0M8HnA1oUe/8HaVmI/Dcez29LFtTcWaWVpOlszbsWa7L8wHUA+YlOXHg/9Fjyd5F1fT0cIDM1QVPXovcWKW7M0ZqjcVjwakutYyuL1f/cVHkdtuMKZr/cTK/3yJMr0HDWTrjYWigTKQA4desJPGdux82wvpVmiYB/bzzCvO2X8GGQN8xNpWjoVAN+8/aV6lof9m6C915siIzsPCiEgI2FGS7eS8EvR29h1ktNYWvBjR2JqismN1VQo1k7ld/HhffDyWI21XvxiwMqr7Nyiu86/PXfWyUmN2N/PolzhRbOA4Ad73dGszr5yYamKbVD27tjZIAn+nxd8gDPC3dTcCMpQ/n6fxNeQNTlRLSsaw+pBMr7lCTstZYI3RytVr72v3jM7d/c4AOLI/+7hZ+P3VIpW/XPTbSpZ4+ezZxLNZ341K3H+OHQTXw1uLWym2XGpvxnLJzYFFY/dAcWvNoSw/zr6Xy/AveSn8JaZgpbC9NiE6WcPAUaf7xTpez0Jz0hM5Wi+ZzdyrKRq46XOhYAmNnHG+92bQBAdQB58zp2WPi6T5muTURVH5MbI3AwpujF6jKeS2a2axgA/LyC7qyiPJ/YACUnHL1buKKpqy0G+dXFzugEnPwkEHlyofIHr8BLy54tyudRywqt3O3Ryt2+xLifN7R9PXyy5QLyFAIX5wap3KvRrJ0GadEQQqB+6A618uZ1bHHxXioAKHeM9naxwaOMHCx4tSXG/pK/Xk/MvN6QmeYnLWlZufhidwwmdGsIZ1sL3HmSqZyZtmv2Lmx+ryOcbS2w6fQdtfvVc7BC/ONM5euP/ozGR39G49ycXrCzzG/RkCsETKQlP//zO94XNSA7V66e2ABA28/3lngPIH8BxvFdGyDlaS72X3mAWjXM0cGrFmIfpKO+o7VKEkNEVBz+ttCT8mr0Vzw3wDYlU7dBqpH/PZtJ0sPbCVFXHqjVWXM0DlMCG2s8X9Ng3JUjfFVe17I2x6Pndun286gJAFj0eisser0VAEBmCkzo1kDZJaXJxncCijymjdgFfZXf753aBT2/OqR8Hf84Ex61NM8oK62IIpbp/3WMv9of+SsJaQCgTGwAoMnHuxDY1Bk/jPRFy/9fn+WX51p/Crz23VGN5bHz+8DURKpcW6iwVnP34OVWdfDXuXvKsrOze8LO0kwl0Vtx8DoCGtRCa3d7tUHjz7fM3VjQF1KpBAOWl25w+psd6mHegGfdhDWtzTHQt67ydQs3u1Jdl4iqr1IlN8nJyfjjjz9w/fp1fPDBB3BwcMDp06fh7OwMNzc3fcdYpbUuRYtDcR6mqw6YnLJe82wlbfw0qh1W/3MTc/9/+fkCNYr5H3LDWer/M+/V3EXl9bHQHghedRzHbjwCADjZyIr8X/cHQd4Y/UJ9APkbXT7/h9RJj3vrNHK2URmX0vWLg5j/agtcf5CBj/s1VVnZuLQW7rqiVlYwiLiFmy0u3E0t8Rr7LidqbP0pyfMtKqF9myK0b1PM3HQe607cVpYXTmyA/LFZZeH10Q58M7SNsmWqKK52Ftg9tQvHwhCRwemc3Jw/fx6BgYGws7NDXFwcxo4dCwcHB2zevBnx8fH45ZdfDBFnpVfUhGVLPS/TPnndWZXXBwp1STV1tcXl+yX/8QTyp74CwOgX6mPhrivIyn3WIvPLsVvo09IVEyJP48LdFOya0hkNnWxwMu6x2nUWv9FKrczcVIrfx3UAADxIzULNElZ1dawhAwD0b1UHi3fHKLtTLswN0upZdPHvRz1UWh4KZmRZy0wwrVfpV04GoDKFuUDhsT1/vNsR/918jKnrz+Lxcy1butg0viMGrlBttTkyo1uR9cMH+mDOy811GuCtyXD/eiotf4UVTkoPf9gN7g75m0cmpWUjO08ON3vLSjOomYiMn0Q8P+WlBIGBgWjbti0WLVoEGxsbnDt3Dl5eXjh69CiGDRuGuLg4A4WqH6mpqbCzs0NKSopyOwl9eH5cQgH/+g5YX8aulcKK2//mr4md0NTVRmPryvMKb4OQJ1fgcWb+mjO6MNQeO09z5JBKoRx7om9r/4vHR3+qDzQu3PKRk6fA01y5cnxKYT8evqG2ou2Vz3srFwoEgEMfdENSejZ8/787rrBcuQK3HmWgoZMNzt1OxvqTtzG9VxNE301B8HMDbfdP64rT8clwtbNATp4C3q42cLVTXYtFoRBatTo9zsjRevzL89aP6wB/r1r49d9b+GRLfkI4tH09jQvmcZFEIjIEXf5+69xyc+LECXz//fdq5W5ubkhIKHpp/OpKp8yxjFrW1X5sQkjPZ2NqTE2kcLKxQEs3O0TfVR8srMn1BX21GoxaGobe6HKYfz2NyU1hY34+gcPXHmLF8LboU2iH5p+O3NS4VH/hxKZuTUvUq2WFerWsNF7bzESKhk756+wUHizdtXFtxIX3Q3JmjrIbz8xECq/aNYqNVdvuNAdrc7XE40pCKoQA+nx9WPms1xLTkCNXoKmLLe4mP4XMVKrsHhzRwQMjOngAyB88HdzRQ7kC9eQejTC1p+axWkRE5Unn5EYmkyE1Vb3r4+rVq6hdm/uvPE/HhjG9+KivNxbseDb2Y+O7AZi6/izuPHm2B5WmP4i6JBWGSmwq0rHrj9DCzRat5u5Bwbjt8ZGn0bu5CyL+f9D059suFXOFfGWZcg2g2Jlq+ubtkv+/n8JJT6NCCxwWdC9pIpFI4O1iy5YaIqp0dF7oo3///vjss8+Qm5s/S0cikSA+Ph4zZszAwIED9R5gVafv3GZA6zol1hnXpQEWDnw2+6Sdp4NKYvN6oZkohb3fXbvds5cNbaNVvcrs+Ec9UNtGho3vPusyHPrDv3j/9zN4fseHXRcT4Dlze7FdggXMTaR4t0sDfYdLREQ60Dm5+fLLL5Geng4nJyc8ffoUXbt2RcOGDWFjY4P58+cbIsYqTZ+5zf/O3sWWs/c0HnN3UB2HMbhdPRwL7Y7rhaZCF5j/quZF+goGGZfk5VYlJ1iVnZOtBU7MCkQ7T9VnPlDMmkGFbXw3AO909cKNBX3R0OlZt9HV+X30MuuKiIhKT+duKTs7O+zduxdHjhzB+fPnkZ6ejrZt2yIwMLDkk6shhZ6abh6lZ6vNlCpgYSbFlvdeUCsvPPDURCpRbkJZ1EBdc9OSc92r8/poEW3VUtPKDE80rBe0a0pntR3NC7TzdFAmRvtCuiI9Ow/WBh4rRERE2in1In6dOnVCp06d9BmLUdJXt1RxqxD/OsYftf5/OnVRYuf3QcTfNzCsffHjQcZ18cLK/1/4zc+jpnJrhx7eTvhpVDsdo64a1o0LQNDSQyplBWvTxIX3w56LCcrNRwHg1MfqiXxxawMREVH50vk38jfffKOxXCKRwMLCAg0bNkSXLl1gYsL/xQLad0ulZ+cV+QcyLSu32N21m7iUvMO1RCLB+BdLHgsS0rMxNp++i4fp2Vj4ug96fJm/gaWpifF2tTRxscH1BX1xL/kpOi86gLVv+6vsO9WruQsuf9Ybf199gE6NajORISKq5HT+Lf3VV18hKSkJmZmZqFkzfw2PJ0+ewMrKCjVq1MCDBw/g5eWFAwcOwN3dXe8BVzXazJbacuYupqw/i4/7NcXbnb3Ujr+15kSR5zrWkOl1xVcLMxOcLNQyMfoFz2K3YzAWJlIJ3B2sipz5Y2lugt4tXDUeIyKiykXnAcULFixAu3btcO3aNTx69AiPHj3C1atX4e/vj6+//hrx8fFwcXHB1KlTDRFvlaNNt9SU9WcBQOP6KZ9uvYgTceq7fm8aH4DQPt6ICula1hCLNfulZrg4NwhNXfW34CEREZEh6dxy8/HHH2PTpk1o0OBZF0fDhg2xePFiDBw4EDdu3MCiRYs4Lfz/lWVA8cV7KVhzNE7jscbONvD10G52U1lIJBJYmbMbhoiIqg6dW27u37+PvLw8tfK8vDzlCsV16tRBWlpa2aMzAmUZUHypmI0Ibbj5IBERkUY6JzfdunXDO++8gzNnnu2jdObMGYwfPx7du3cHAERHR6N+/fr6i7IKK8tkqRy5ouRKREREpELn5Oann36Cg4MDfH19IZPJIJPJ4OfnBwcHB/z0008AgBo1auDLL7/Ue7BVUVm2X3C1s9BjJERERNWDzoMpXFxcsHfvXly5cgVXr14FADRp0gRNmjRR1unWrZv+IqziytItlZWrueVm7dv+pb8oERGRkSv1SFFvb294e3vrMxajVJYBxU9z5Cqvoz/thccZOfCoZV3WsIiIiIxWqZKbO3fuYOvWrYiPj0dOTo7KsSVLluglMGNRUmqTmqW+7H+BrDzV5MbGwowDiYmIiEqgc3ITFRWF/v37w8vLC1euXEGLFi0QFxcHIQTatm1riBirhKLW7y1pzI0oZszw8y03REREVDKdBxSHhoZi+vTpiI6OhoWFBTZt2oTbt2+ja9eueOONNwwRY5VWUq/U891WhZOh1KdFt+oQERGRZjonN5cvX8bIkSMBAKampnj69Clq1KiBzz77DAsXLtR7gFXdjYcZxR5Pz1ZdMyhP8Sy5+WZ/LADAzd5S42aNREREpE7n5Mba2lo5zsbV1RXXr19XHnv48KH+IjMixXVNPZ/cpGflv76f8lRZJjOTlrjrNxEREeXTObnp0KEDjhw5AgDo27cvpk2bhvnz5+Ott95Chw4ddA5g+fLl8PT0hIWFBfz9/XH8+PEi6168eBEDBw6Ep6cnJBIJli5dqvP9KkJxXVPPJzf3/j+pCQjbryy7kVR86w8RERE9o3Nys2TJEvj756+zMnfuXPTo0QPr16+Hp6enchE/ba1fvx4hISGYM2cOTp8+jVatWiEoKAgPHjzQWD8zMxNeXl4IDw+Hi4uLrqFXCg/SsrD+RLxysHBBS00BmalJRYRFRERkNHRKbuRyOe7cuYN69eoByO+iioiIwPnz57Fp0yZ4eHjodPMlS5Zg7NixGD16NJo1a4aIiAhYWVlh1apVGuu3a9cOX3zxBYYMGQKZrOp00xRuuBm44ihmbIrGmz/9B0C95WbLmbtq5/fwdjJkeEREREZFp+TGxMQEvXr1wpMnT8p845ycHJw6dQqBgc8GykqlUgQGBuLYsWNlvn6B7OxspKamqnyVt8Jjbm4/zu92OnXrCRJTs9SSm28PxEKhUO3H+u7N6jvFnoiISFc6d0u1aNECN27cKPONHz58CLlcDmdnZ5VyZ2dn5e7i+hAWFgY7Ozvll7u7u96uXVhxM76LOnbnyVO1bikAeJypujAiu6qIiIi0p3NyM2/ePEyfPh3btm3D/fv3K7xVpCShoaFISUlRft2+fbuiQ1KyNDPBk+cSGQDwm7dP+f2PI/3KMyQiIqIqT+cVivv27QsA6N+/PySSZ+vyCiEgkUggl2u3qq6joyNMTEyQmJioUp6YmKjXwcIFO5dXpKJmS208dRur/4kr9tzAZs7FHiciIiJVOic3Bw4c0MuNzc3N4evri6ioKAwYMAAAoFAoEBUVhYkTJ+rlHpWFKKJjqqTEhoiIiHSnc3LTtWtXvd08JCQEwcHB8PPzQ/v27bF06VJkZGRg9OjRAICRI0fCzc0NYWFhAPIHIV+6dEn5/d27d3H27FnUqFEDDRs21Ftc+laGjcGJiIhIR6XaFfzw4cP4/vvvcePGDWzcuBFubm749ddfUb9+fXTq1Enr6wwePBhJSUmYPXs2EhIS0Lp1a+zatUs5yDg+Ph5S6bNhQffu3UObNm2UrxcvXozFixeja9euOHjwYGkepVw9PzOKiIiI9E/nAcWbNm1CUFAQLC0tcfr0aWRnZwMAUlJSsGDBAp0DmDhxIm7duoXs7Gz8999/ygUCAeDgwYNYs2aN8rWnpyeEEGpflT2xKWi5ufvkaZF13u9eeVueiIiIqpJSzZaKiIjADz/8ADMzM2X5Cy+8gNOnT+s1OGNR1Jibwu6nZKmVFRqvTURERFrSObmJiYlBly5d1Mrt7OyQnJysj5iMTkHLTXFJjkctK7Wy+QNaGiokIiIio6VzcuPi4oLY2Fi18iNHjsDLy0svQRmbgpTm9K3kIuto2vV7SDvDLDhIRERkzHRObsaOHYvJkyfjv//+g0Qiwb179xAZGYnp06dj/PjxhoixyivYfuHag7Qi67zaxk2tTCplvxQREZGudJ4tNXPmTCgUCvTo0QOZmZno0qULZDIZpk+fjkmTJhkixiqvoOXG2rzot9vCjFssEBER6YPOyY1EIsGsWbPwwQcfIDY2Funp6WjWrBlq1KhhiPiMQsGYm1yFQuPx4f711Mpe8nE1ZEhERERGS+duqd9++w2ZmZkwNzdHs2bN0L59eyY2AIrtQPr/5KaNe02Nh+e/qjpw2MJMim+GtNFYl4iIiIqnc3IzdepUODk5YdiwYdixY4fWe0lVZwWzpOwszUqomc+nrj3H2xAREZWSzsnN/fv3sW7dOkgkEgwaNAiurq6YMGECjh49aoj4jEJBt5SihH0YChbym9W3qaFDIiIiMlo6JzempqZ46aWXEBkZiQcPHuCrr75CXFwcunXrhgYNGhgixipv7fF49PvmsMaF+goL6dUEMfN6o5W7ffkERkREZIRKtbdUASsrKwQFBeHJkye4desWLl++rK+4jMoXu2MAAJ9uvQgAaOZqi0v3UzXWlZly1hQREVFZ6NxyAwCZmZmIjIxE37594ebmhqVLl+LVV1/FxYsX9R2fUSnYONPctFRvOxEREWlB55abIUOGYNu2bbCyssKgQYPwySefICAgwBCxGS0TDhYmIiIyGJ2TGxMTE2zYsAFBQUEwMVHtQrlw4QJatGiht+CqOonk2WDiwqLvpJR/MERERNWEzslNZGSkyuu0tDT8/vvv+PHHH3Hq1ClODS9EKpFAriG7yZFrXsyPiIiIyq7Ugz8OHTqE4OBguLq6YvHixejevTv+/fdffcZW5bHziYiIqPzp1HKTkJCANWvW4KeffkJqaioGDRqE7OxsbNmyBc2aNTNUjFWWhNkNERFRudO65ebll19GkyZNcP78eSxduhT37t3DsmXLDBlblSdh2w0REVG507rlZufOnXj//fcxfvx4NGrUyJAxGQ/mNkREROVO65abI0eOIC0tDb6+vvD398e3336Lhw8fGjK2KkXTxgrMbYiIiMqf1slNhw4d8MMPP+D+/ft45513sG7dOtSpUwcKhQJ79+5FWlqaIeOskooac+Nf36F8AyEiIqpGdJ4tZW1tjbfeegtHjhxBdHQ0pk2bhvDwcDg5OaF///6GiLHKKmrMTTdvp3KOhIiIqPoo0z4ATZo0waJFi3Dnzh38/vvv+orJaBTVciMBML1XYwDA6Bc8yy0eIiKi6qBMG2cWMDExwYABAzBgwAB9XM5oFDXmRiIBJnRriD4tXVG/lnW5xkRERGTs9JLckGaSIppuJJBAIpGgQe0a5RwRERGR8eP21AZUXMsNERERGQaTGz3RmK8wiSEiIip3TG4MiLkNERFR+WNyY0BFjbmRmZmUcyRERETVB5MbAypqbM3rbeuWbyBERETVCJMbAyqqW8rSnC03REREhsLkxoCK6pYiIiIiw2FyY0BMbYiIiMofkxsDYsMNERFR+WNyY1Dq2c20no0rIA4iIqLqg8mNAWlqubG1NCv/QIiIiKoRJjcGpKlXqru3U7nHQUREVJ1w40wDer7l5sSsQNS2kVVMMERERNUEW24MSPJc2w0TGyIiIsNjcmNAnC1FRERU/pjcGJCU2Q0REVG5qxTJzfLly+Hp6QkLCwv4+/vj+PHjxdbfuHEjvL29YWFhgZYtW2LHjh3lFKlu7iY/regQiIiIqp0KT27Wr1+PkJAQzJkzB6dPn0arVq0QFBSEBw8eaKx/9OhRDB06FGPGjMGZM2cwYMAADBgwABcuXCjnyHVjKmUrDhERUXmQCCFERQbg7++Pdu3a4dtvvwUAKBQKuLu7Y9KkSZg5c6Za/cGDByMjIwPbtm1TlnXo0AGtW7dGREREifdLTU2FnZ0dUlJSYGtrq7fn+OvcPUz6/UyRx/eFdEVDpxp6ux8REVF1osvf7wptucnJycGpU6cQGBioLJNKpQgMDMSxY8c0nnPs2DGV+gAQFBRUZP3Kwt3BsqJDICIiqhYqdJ2bhw8fQi6Xw9nZWaXc2dkZV65c0XhOQkKCxvoJCQka62dnZyM7O1v5OjU1tYxRa1ZDVvxbaSat8B5AIiKiasHo/+KGhYXBzs5O+eXu7m6Q+3RtXBuvtXUr8riUY26IiIjKRYUmN46OjjAxMUFiYqJKeWJiIlxcXDSe4+LiolP90NBQpKSkKL9u376tn+CfI5VKsGRQa4Ncm4iIiLRXocmNubk5fH19ERUVpSxTKBSIiopCQECAxnMCAgJU6gPA3r17i6wvk8lga2ur8kVERETGq8L3lgoJCUFwcDD8/PzQvn17LF26FBkZGRg9ejQAYOTIkXBzc0NYWBgAYPLkyejatSu+/PJL9OvXD+vWrcPJkyexcuXKinwMIiIiqiQqPLkZPHgwkpKSMHv2bCQkJKB169bYtWuXctBwfHw8pIUG43bs2BFr167Fxx9/jI8++giNGjXCli1b0KJFi4p6BCIiIqpEKnydm/JmqHVuCnjO3K6xPC68n97vRUREVF1UmXVuiIiIiPSNyY2effpyMwDA+90bVnAkRERE1VOFj7kxNqNeqI++Pq5wsrHAN/tjKzocIiKiaoctNwbgZGNR0SEQERFVW0xuiIiIyKgwuSEiIiKjwuSGiIiIjAqTGyIiIjIqTG6IiIjIqDC5ISIiIqPC5IaIiIiMCpMbIiIiMipMbspB3ZqWFR0CERFRtcHkphzUtDKv6BCIiIiqDSY35cDCjG8zERFReeFfXQP64nUfeNayQvhAn4oOhYiIqNrgruAG9IafO97wc6/oMIiIiKoVttwQERGRUWFyQ0REREaFyQ0REREZFSY3REREZFSY3BAREZFRYXJDRERERoXJDRERERkVJjdERERkVJjcEBERkVFhckNERERGhckNERERGRUmN0RERGRUmNwQERGRUWFyQ0REREbFtKIDKG9CCABAampqBUdCRERE2ir4u13wd7w41S65SUtLAwC4u7tXcCRERESkq7S0NNjZ2RVbRyK0SYGMiEKhwL1792BjYwOJRKLXa6empsLd3R23b9+Gra2tXq9dWfGZq8czA9XzufnMfGZjVRWfWQiBtLQ01KlTB1Jp8aNqql3LjVQqRd26dQ16D1tb2yrzw6IvfObqozo+N5+5euAzV34ltdgU4IBiIiIiMipMboiIiMioMLnRI5lMhjlz5kAmk1V0KOWGz1x9VMfn5jNXD3xm41PtBhQTERGRcWPLDRERERkVJjdERERkVJjcEBERkVFhckNERERGhcmNnixfvhyenp6wsLCAv78/jh8/XtEhaS0sLAzt2rWDjY0NnJycMGDAAMTExKjUefHFFyGRSFS+3n33XZU68fHx6NevH6ysrODk5IQPPvgAeXl5KnUOHjyItm3bQiaToWHDhlizZo2hH0+jTz/9VO15vL29lcezsrIwYcIE1KpVCzVq1MDAgQORmJioco2q9LwA4OnpqfbMEokEEyZMAGAcn/GhQ4fw8ssvo06dOpBIJNiyZYvKcSEEZs+eDVdXV1haWiIwMBDXrl1TqfP48WMMHz4ctra2sLe3x5gxY5Cenq5S5/z58+jcuTMsLCzg7u6ORYsWqcWyceNGeHt7w8LCAi1btsSOHTv0/rwFinvu3NxczJgxAy1btoS1tTXq1KmDkSNH4t69eyrX0PTzER4erlKnMj13SZ/1qFGj1J6nd+/eKnWq2mdd0jNr+vctkUjwxRdfKOtUtc+51ASV2bp164S5ublYtWqVuHjxohg7dqywt7cXiYmJFR2aVoKCgsTq1avFhQsXxNmzZ0Xfvn1FvXr1RHp6urJO165dxdixY8X9+/eVXykpKcrjeXl5okWLFiIwMFCcOXNG7NixQzg6OorQ0FBlnRs3bggrKysREhIiLl26JJYtWyZMTEzErl27yvV5hRBizpw5onnz5irPk5SUpDz+7rvvCnd3dxEVFSVOnjwpOnToIDp27Kg8XtWeVwghHjx4oPK8e/fuFQDEgQMHhBDG8Rnv2LFDzJo1S2zevFkAEH/++afK8fDwcGFnZye2bNkizp07J/r37y/q168vnj59qqzTu3dv0apVK/Hvv/+Kw4cPi4YNG4qhQ4cqj6ekpAhnZ2cxfPhwceHCBfH7778LS0tL8f333yvr/PPPP8LExEQsWrRIXLp0SXz88cfCzMxMREdHl/tzJycni8DAQLF+/Xpx5coVcezYMdG+fXvh6+urcg0PDw/x2WefqXz+hX8HVLbnLumzDg4OFr1791Z5nsePH6vUqWqfdUnPXPhZ79+/L1atWiUkEom4fv26sk5V+5xLi8mNHrRv315MmDBB+Voul4s6deqIsLCwCoyq9B48eCAAiL///ltZ1rVrVzF58uQiz9mxY4eQSqUiISFBWbZixQpha2srsrOzhRBCfPjhh6J58+Yq5w0ePFgEBQXp9wG0MGfOHNGqVSuNx5KTk4WZmZnYuHGjsuzy5csCgDh27JgQouo9ryaTJ08WDRo0EAqFQghhfJ/x87/8FQqFcHFxEV988YWyLDk5WchkMvH7778LIYS4dOmSACBOnDihrLNz504hkUjE3bt3hRBCfPfdd6JmzZrKZxZCiBkzZogmTZooXw8aNEj069dPJR5/f3/xzjvv6PUZNdH0R+95x48fFwDErVu3lGUeHh7iq6++KvKcyvzcRSU3r7zySpHnVPXPWpvP+ZVXXhHdu3dXKavKn7Mu2C1VRjk5OTh16hQCAwOVZVKpFIGBgTh27FgFRlZ6KSkpAAAHBweV8sjISDg6OqJFixYIDQ1FZmam8tixY8fQsmVLODs7K8uCgoKQmpqKixcvKusUfp8K6lTU+3Tt2jXUqVMHXl5eGD58OOLj4wEAp06dQm5urkqs3t7eqFevnjLWqvi8heXk5OC3337DW2+9pbKBrLF9xoXdvHkTCQkJKvHZ2dnB399f5XO1t7eHn5+fsk5gYCCkUin+++8/ZZ0uXbrA3NxcWScoKAgxMTF48uSJsk5lfR+A/H/jEokE9vb2KuXh4eGoVasW2rRpgy+++EKly7EqPvfBgwfh5OSEJk2aYPz48Xj06JHymLF/1omJidi+fTvGjBmjdszYPmdNqt3Gmfr28OFDyOVylV/4AODs7IwrV65UUFSlp1AoMGXKFLzwwgto0aKFsnzYsGHw8PBAnTp1cP78ecyYMQMxMTHYvHkzACAhIUHje1BwrLg6qampePr0KSwtLQ35aCr8/f2xZs0aNGnSBPfv38fcuXPRuXNnXLhwAQkJCTA3N1f7xe/s7FzisxQcK65ORTzv87Zs2YLk5GSMGjVKWWZsn/HzCmLUFF/h+J2cnFSOm5qawsHBQaVO/fr11a5RcKxmzZpFvg8F16hIWVlZmDFjBoYOHaqyYeL777+Ptm3bwsHBAUePHkVoaCju37+PJUuWAKh6z927d2+89tprqF+/Pq5fv46PPvoIffr0wbFjx2BiYmL0n/XPP/8MGxsbvPbaayrlxvY5F4XJDamYMGECLly4gCNHjqiUjxs3Tvl9y5Yt4erqih49euD69eto0KBBeYdZZn369FF+7+PjA39/f3h4eGDDhg0V+ge4vPz000/o06cP6tSpoywzts+Y1OXm5mLQoEEQQmDFihUqx0JCQpTf+/j4wNzcHO+88w7CwsKq5BL9Q4YMUX7fsmVL+Pj4oEGDBjh48CB69OhRgZGVj1WrVmH48OGwsLBQKTe2z7ko7JYqI0dHR5iYmKjNpElMTISLi0sFRVU6EydOxLZt23DgwAHUrVu32Lr+/v4AgNjYWACAi4uLxveg4FhxdWxtbSs8obC3t0fjxo0RGxsLFxcX5OTkIDk5WaVO4c+0Kj/vrVu3sG/fPrz99tvF1jO2z7ggxuL+rbq4uODBgwcqx/Py8vD48WO9fPYV+TuhILG5desW9u7dq9Jqo4m/vz/y8vIQFxcHoOo+dwEvLy84Ojqq/Dwb62d9+PBhxMTElPhvHDC+z7kAk5syMjc3h6+vL6KiopRlCoUCUVFRCAgIqMDItCeEwMSJE/Hnn39i//79ak2Smpw9exYA4OrqCgAICAhAdHS0yi+Lgl+gzZo1U9Yp/D4V1KkM71N6ejquX78OV1dX+Pr6wszMTCXWmJgYxMfHK2Otys+7evVqODk5oV+/fsXWM7bPuH79+nBxcVGJLzU1Ff/995/K55qcnIxTp04p6+zfvx8KhUKZ7AUEBODQoUPIzc1V1tm7dy+aNGmCmjVrKutUpvehILG5du0a9u3bh1q1apV4ztmzZyGVSpVdN1XxuQu7c+cOHj16pPLzbIyfNZDfMuvr64tWrVqVWNfYPmelih7RbAzWrVsnZDKZWLNmjbh06ZIYN26csLe3V5lVUpmNHz9e2NnZiYMHD6pMD8zMzBRCCBEbGys+++wzcfLkSXHz5k3xv//9T3h5eYkuXboor1EwTbhXr17i7NmzYteuXaJ27doapwl/8MEH4vLly2L58uUVNjV62rRp4uDBg+LmzZvin3/+EYGBgcLR0VE8ePBACJE/FbxevXpi//794uTJkyIgIEAEBARU2ectIJfLRb169cSMGTNUyo3lM05LSxNnzpwRZ86cEQDEkiVLxJkzZ5SzgsLDw4W9vb343//+J86fPy9eeeUVjVPB27RpI/777z9x5MgR0ahRI5XpwcnJycLZ2VmMGDFCXLhwQaxbt05YWVmpTZU1NTUVixcvFpcvXxZz5swx6FTZ4p47JydH9O/fX9StW1ecPXtW5d94wYyYo0ePiq+++kqcPXtWXL9+Xfz222+idu3aYuTIkZX2uYt75rS0NDF9+nRx7NgxcfPmTbFv3z7Rtm1b0ahRI5GVlaW8RlX7rEv6+RYifyq3lZWVWLFihdr5VfFzLi0mN3qybNkyUa9ePWFubi7at28v/v3334oOSWsANH6tXr1aCCFEfHy86NKli3BwcBAymUw0bNhQfPDBByproAghRFxcnOjTp4+wtLQUjo6OYtq0aSI3N1elzoEDB0Tr1q2Fubm58PLyUt6jvA0ePFi4uroKc3Nz4ebmJgYPHixiY2OVx58+fSree+89UbNmTWFlZSVeffVVcf/+fZVrVKXnLbB7924BQMTExKiUG8tnfODAAY0/y8HBwUKI/Ongn3zyiXB2dhYymUz06NFD7b149OiRGDp0qKhRo4awtbUVo0ePFmlpaSp1zp07Jzp16iRkMplwc3MT4eHharFs2LBBNG7cWJibm4vmzZuL7du3V8hz37x5s8h/4wVrHJ06dUr4+/sLOzs7YWFhIZo2bSoWLFigkghUtucu7pkzMzNFr169RO3atYWZmZnw8PAQY8eOVfsPZ1X7rEv6+RZCiO+//15YWlqK5ORktfOr4udcWhIhhDBo0xARERFROeKYGyIiIjIqTG6IiIjIqDC5ISIiIqPC5IaIiIiMCpMbIiIiMipMboiIiMioMLkhIiIio8LkhoiqhLi4OEgkEuW2EIYwatQoDBgwwGDXJ6LyweSGiMrFqFGjIJFI1L569+6t1fnu7u64f/8+WrRoYeBIiaiqM63oAIio+ujduzdWr16tUiaTybQ618TEpFLtOkxElRdbboio3MhkMri4uKh8Few0LJFIsGLFCvTp0weWlpbw8vLCH3/8oTz3+W6pJ0+eYPjw4ahduzYsLS3RqFEjlcQpOjoa3bt3h6WlJWrVqoVx48YhPT1deVwulyMkJAT29vaoVasWPvzwQzy/G41CoUBYWBjq168PS0tLtGrVSiUmIqqcmNwQUaXxySefYODAgTh37hyGDx+OIUOG4PLly0XWvXTpEnbu3InLly9jxYoVcHR0BABkZGQgKCgINWvWxIkTJ7Bx40bs27cPEydOVJ7/5ZdfYs2aNVi1ahWOHDmCx48f488//1S5R1hYGH755RdERETg4sWLmDp1Kt588038/fffhnsTiKjsKnjjTiKqJoKDg4WJiYmwtrZW+Zo/f74QIn93+nfffVflHH9/fzF+/HghhFDubn3mzBkhhBAvv/yyGD16tMZ7rVy5UtSsWVOkp6cry7Zv3y6kUqlyZ2hXV1exaNEi5fHc3FxRt25d8corrwghhMjKyhJWVlbi6NGjKtceM2aMGDp0aOnfCCIyOI65IaJy061bN6xYsUKlzMHBQfl9QECAyrGAgIAiZ0eNHz8eAwcOxOnTp9GrVy8MGDAAHTt2BABcvnwZrVq1grW1tbL+Cy+8AIVCgZiYGFhYWOD+/fvw9/dXHjc1NYWfn5+yayo2NhaZmZno2bOnyn1zcnLQpk0b3R+eiMoNkxsiKjfW1tZo2LChXq7Vp08f3Lp1Czt27MDevXvRo0cPTJgwAYsXL9bL9QvG52zfvh1ubm4qx7QdBE1EFYNjboio0vj333/VXjdt2rTI+rVr10ZwcDB+++03LF26FCtXrgQANG3aFOfOnUNGRoay7j///AOpVIomTZrAzs4Orq6u+O+//5TH8/LycOrUKeXrZs2aQSaTIT4+Hg0bNlT5cnd319cjE5EBsOWGiMpNdnY2EhISVMpMTU2VA4E3btwIPz8/dOrUCZGRkTh+/Dh++uknjdeaPXs2fH190bx5c2RnZ2Pbtm3KRGj48OGYM2cOgoOD8emnnyIpKQmTJk3CiBEj4OzsDACYPHkywsPD0ahRI3h7e2PJkiVITk5WXt/GxgbTp0/H1KlToVAo0KlTJ6SkpOCff/6Bra0tgoODDfAOEZE+MLkhonKza9cuuLq6qpQ1adIEV65cAQDMnTsX69atw3vvvQdXV1f8/vvvaNasmcZrmZubIzQ0FHFxcbC0tETnzp2xbt06AICVlRV2796NyZMno127drCyssLAgQOxZMkS5fnTpk3D/fv3ERwcDKlUirfeeguvvvoqUlJSlHU+//xz1K5dG2FhYbhx4wbs7e3Rtm1bfPTRR/p+a4hIjyRCPLewAxFRBZBIJPjzzz+5/QERlRnH3BAREZFRYXJDRERERoVjboioUmAPORHpC1tuiIiIyKgwuSEiIiKjwuSGiIiIjAqTGyIiIjIqTG6IiIjIqDC5ISIiIqPC5IaIiIiMCpMbIiIiMipMboiIiMio/B/Ao9POd7GIKQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "└─────────┘\n",
            "Stack at Start:  7.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  32.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 45 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.0\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  3.5\n",
            "\n",
            "\n",
            "============================= Round 46 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  31.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  31.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 47 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  33.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 48 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 49 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 50 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  32.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 51 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  33.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  33.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 52 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  31.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 53 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  32.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  32.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  8.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 54 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Players Split The Pot: To Each Are Returned:  3.5\n",
            "\n",
            "\n",
            "============================= Round 55 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 56 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  36.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  36.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Players Split The Pot: To Each Are Returned:  1.5\n",
            "\n",
            "\n",
            "============================= Round 57 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  36.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 58 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  36.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  36.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  3.5\n",
            "\n",
            "\n",
            "============================= Round 59 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  33.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  7.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 60 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  34.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  34.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  3.5\n",
            "\n",
            "\n",
            "============================= Round 61 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  31.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  9.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  31.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  31.0\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  9.0\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 62 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  33.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  6.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 63 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 64 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  35.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 65 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  36.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  36.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  36.0\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.0\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 66 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  38.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.5\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  38.5\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 67 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  37.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  37.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 68 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  34.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 69 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Stack at Start:  35.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  5.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 70 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  35.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  35.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  4.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 71 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  38.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 72 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  38.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.5\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  38.5\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 73 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  37.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 74 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  37.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  37.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 75 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  39.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  39.0\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  3.5 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  39.0\n",
            "In Chips:  2.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.0\n",
            "In Chips:  1.0\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 76 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  36.5\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: check\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  36.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  3.5\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 77 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  39.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.0\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  2.5 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  39.0\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.0\n",
            "In Chips:  1.0\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 78 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.25\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  38.75\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  2.75 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.25\n",
            "In Chips:  1.25\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  38.75\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 79 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  37.25\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.75\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: raise\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  37.25\n",
            "In Chips:  1.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  5.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Stack at Start:  37.25\n",
            "In Chips:  2.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  2.75\n",
            "In Chips:  2.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: fold\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "Winner due to fold\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│Q        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        Q│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  2.5\n",
            "\n",
            "\n",
            "============================= Round 80 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  0.75 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  0.25\n",
            "In Chips:  0.25\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  39.75\n",
            "In Chips:  0.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  0.75 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  0.25\n",
            "In Chips:  0.25\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  39.75\n",
            "In Chips:  0.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 81 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  0.875 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  39.625\n",
            "In Chips:  0.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  0.375\n",
            "In Chips:  0.375\n",
            "Simulate to end as player is all in\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  0.875 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Stack at Start:  39.625\n",
            "In Chips:  0.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  0.375\n",
            "In Chips:  0.375\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│10       │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│       01│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│J        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♦    │\n",
            "│         │\n",
            "│         │\n",
            "│        J│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  0.5\n",
            "\n",
            "\n",
            "============================= Round 82 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  0.875\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  39.125\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  2.375 \n",
            "\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  0.875\n",
            "In Chips:  0.875\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Stack at Start:  39.125\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♥    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  wins:  1.5\n",
            "\n",
            "\n",
            "============================= Round 83 =============================\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "│░░░░░░░░░│   │░░░░░░░░░│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  1.0 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  38.8125\n",
            "In Chips:  0.5\n",
            "Legal actions: ['check', 'bet']\n",
            "Action chosen: bet\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.1875\n",
            "In Chips:  0.5\n",
            "Legal actions: ['fold', 'call', 'raise']\n",
            "Action chosen: call\n",
            "\n",
            "================= Public Cards =================\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Pot:  2.6875 \n",
            "\n",
            "\n",
            "========= Player:  Q-Learning Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Stack at Start:  38.8125\n",
            "In Chips:  1.5\n",
            "Simulate to end as player is all in\n",
            "\n",
            "========= Player:  Threshold Tight Agent  =========\n",
            "Card: \n",
            "┌─────────┐\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "│░░░░░░░░░│\n",
            "└─────────┘\n",
            "Stack at Start:  1.1875\n",
            "In Chips:  1.1875\n",
            "Simulate to end as player is all in\n",
            "\n",
            "\n",
            "==================== Showdown =================\n",
            "\n",
            "Public Cards:\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "Player  Q-Learning Agent  Hand: \n",
            "┌─────────┐\n",
            "│A        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♣    │\n",
            "│         │\n",
            "│         │\n",
            "│        A│\n",
            "└─────────┘\n",
            "Player  Threshold Tight Agent  Hand: \n",
            "┌─────────┐\n",
            "│K        │\n",
            "│         │\n",
            "│         │\n",
            "│    ♠    │\n",
            "│         │\n",
            "│         │\n",
            "│        K│\n",
            "└─────────┘\n",
            "Player  Q-Learning Agent  wins:  1.1875\n",
            "\n",
            "\n",
            "The Player  Threshold Tight Agent  Is Bankrupt!\n",
            "Therefore The Winner Is  Q-Learning Agent\n",
            "Average reward at the end of the game for Agent: 0.23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}